{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import keras\n",
    "import pandas as pd\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Dropout, Activation, Embedding\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Import libraries\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk \n",
    "# nltk.download()\n",
    "import string\n",
    "import re\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "3   6     NaN      NaN   \n",
       "4   7     NaN      NaN   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0                                Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                               Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...   \n",
       "3                                    13,000 people receive #wildfires evacuation orders in California    \n",
       "4             Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./nlp-getting-started/train.csv', encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residents asked shelter place notified officers evacuation shelter place orders expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pours school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant cranes holding bridge collapse nearby homes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ariaahrary thetawniest control wild fires california even northern part state troubling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police investigating ebike collided car little portugal ebike rider suffered serious nonlife thr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>latest homes razed northern california wildfire abc news</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                                                                     text  \\\n",
       "0                                                            deeds reason earthquake may allah forgive us   \n",
       "1                                                                   forest fire near la ronge sask canada   \n",
       "2                residents asked shelter place notified officers evacuation shelter place orders expected   \n",
       "3                                                  people receive wildfires evacuation orders california    \n",
       "4                                                got sent photo ruby alaska smoke wildfires pours school    \n",
       "...                                                                                                   ...   \n",
       "7608                                               two giant cranes holding bridge collapse nearby homes    \n",
       "7609              ariaahrary thetawniest control wild fires california even northern part state troubling   \n",
       "7610                                                                                      volcano hawaii    \n",
       "7611  police investigating ebike collided car little portugal ebike rider suffered serious nonlife thr...   \n",
       "7612                                            latest homes razed northern california wildfire abc news    \n",
       "\n",
       "      target  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "7608       1  \n",
       "7609       1  \n",
       "7610       1  \n",
       "7611       1  \n",
       "7612       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### removing entries where location values are missing\n",
    "data_after_null_removal = data.copy()\n",
    "\n",
    "#punctutation removal\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "data_afer_punctuation_removal = data_after_null_removal.copy()\n",
    "data_afer_punctuation_removal['text'] = data_afer_punctuation_removal['text'].apply(lambda x: clean_text(x))\n",
    "data_afer_punctuation_removal.head(10)\n",
    "\n",
    "# Tockenization\n",
    "\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "tockenized_data = data_afer_punctuation_removal.copy()\n",
    "tockenized_data['text'] = tockenized_data['text'].apply(lambda x: tokenization(x.lower()))\n",
    "\n",
    "# stopword removal \n",
    "data_after_stopword_removal = tockenized_data.copy()\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "data_after_stopword_removal['text'] = data_after_stopword_removal['text'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# return to string\n",
    "data_without_tockenization = data_after_stopword_removal.copy()\n",
    "def listToString(s):     \n",
    "    # initialize an empty string \n",
    "    str1 = \" \" \n",
    "    # return string   \n",
    "    return (str1.join(s)) \n",
    "        \n",
    "data_without_tockenization['text'] = data_without_tockenization['text'].apply(lambda x: listToString(x))\n",
    "data_without_tockenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_without_tockenization.copy()\n",
    "\n",
    "sentences = df['text'].values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, \n",
    "                                                                    y, test_size=0.1, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6851x15374 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 59212 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences_train)\n",
    "\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cooking earlier got electrocuted crucial im psychic lol\n",
      "[1413, 28, 358, 3, 82]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "print(sentences_train[2])\n",
    "print(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('./nlp-getting-started/glove.twitter.27B/glove.twitter.27B.50d.txt',\n",
    "                                           tokenizer.word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 50)           769850    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 770,371\n",
      "Trainable params: 521\n",
      "Non-trainable params: 769,850\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, \n",
    "                           weights=[embedding_matrix], \n",
    "                           input_length=maxlen, \n",
    "                           trainable=False))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy','Precision','Recall'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "686/686 [==============================] - 7s 10ms/step - loss: 0.6159 - accuracy: 0.6722 - precision: 0.6315 - recall: 0.5635 - val_loss: 0.5717 - val_accuracy: 0.7270 - val_precision: 0.7336 - val_recall: 0.5982\n",
      "Epoch 2/50\n",
      "686/686 [==============================] - 4s 6ms/step - loss: 0.5417 - accuracy: 0.7349 - precision: 0.7034 - recall: 0.6593 - val_loss: 0.5239 - val_accuracy: 0.7454 - val_precision: 0.7305 - val_recall: 0.6696\n",
      "Epoch 3/50\n",
      "686/686 [==============================] - 5s 7ms/step - loss: 0.5116 - accuracy: 0.7542 - precision: 0.7277 - recall: 0.6811 - val_loss: 0.5068 - val_accuracy: 0.7467 - val_precision: 0.6917 - val_recall: 0.7679\n",
      "Epoch 4/50\n",
      "686/686 [==============================] - 6s 9ms/step - loss: 0.4979 - accuracy: 0.7662 - precision: 0.7398 - recall: 0.7005 - val_loss: 0.4916 - val_accuracy: 0.7835 - val_precision: 0.7785 - val_recall: 0.7113\n",
      "Epoch 5/50\n",
      "686/686 [==============================] - 5s 7ms/step - loss: 0.4895 - accuracy: 0.7673 - precision: 0.7427 - recall: 0.6991 - val_loss: 0.4881 - val_accuracy: 0.7848 - val_precision: 0.7792 - val_recall: 0.7143\n",
      "Epoch 6/50\n",
      "686/686 [==============================] - 4s 6ms/step - loss: 0.4880 - accuracy: 0.7735 - precision: 0.7517 - recall: 0.7036 - val_loss: 0.4852 - val_accuracy: 0.7848 - val_precision: 0.7756 - val_recall: 0.7202\n",
      "Epoch 7/50\n",
      "686/686 [==============================] - 4s 6ms/step - loss: 0.4846 - accuracy: 0.7762 - precision: 0.7545 - recall: 0.7080 - val_loss: 0.4855 - val_accuracy: 0.7861 - val_precision: 0.7799 - val_recall: 0.7173\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model!\n"
     ]
    }
   ],
   "source": [
    "glove_model = model.to_json()\n",
    "with open('./NN_Models/glove_mlp_model.json', 'w') as json_file:\n",
    "    json_file.write(glove_model)\n",
    "\n",
    "model.save_weights('./NN_Models/glove_mlp_model.h5')\n",
    "\n",
    "print('saved model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training and Validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.47785547375679016,\n",
       " 0.7793022990226746,\n",
       " 0.7638116478919983,\n",
       " 0.7018739581108093]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-75a57132f8cc>:2: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>358</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>95</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative  Positive\n",
       "Negative       358        68\n",
       "Positive        95       241"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "Y_pred = model.predict_generator(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "def rounding(results):\n",
    "    '''Results needs to be rounded to 0 or 1 for fake or real, respectively'''\n",
    "    if results < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "predictions_final = [rounding(x) for x in Y_pred]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_final).ravel()\n",
    "precision= tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tn + fp +fn+tp)\n",
    "falsePositiveRate = fp / (fp + tn)\n",
    "recall = tp/(tp+fn)\n",
    "f1= 2 * ((recall*precision)/(recall+precision))\n",
    "\n",
    "# Intialise data to Dicts of series. \n",
    "d = {'Value' : pd.Series([accuracy, precision, falsePositiveRate, recall,f1], index =['Accuracy', 'Precision', 'FPR','Recall','F1'])} \n",
    "  \n",
    "# creates Dataframe. \n",
    "results = pd.DataFrame(d) \n",
    "  \n",
    "\n",
    "data = {'Negative':[tn, fn], 'Positive':[fp, tp]} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df= pd.DataFrame(data, index =['Negative', 'Positive']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.786089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.779935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.159624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.717262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.747287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "Accuracy   0.786089\n",
       "Precision  0.779935\n",
       "FPR        0.159624\n",
       "Recall     0.717262\n",
       "F1         0.747287"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Accuracy and precision increased by just 1%\n",
    "- Recall also improved by 2%\n",
    "- F1 has also slightly increased\n",
    "- This model is slightly better than the keras embedding layer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explore\n",
    "\n",
    "- try and find a location in a tweet text and see if we can match that to the location column.\n",
    "- be careful with places like east london.\n",
    "- see if the user is within the radius of the location in the tweet itself(i.e. if a user retweets from melville about a tweet in braamfontein it could be legit, but it is not if the user is in london).\n",
    "\n",
    "- tweets with mislabels: exclude these since they might hurt our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data_without_tockenization.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, \n",
    "                                                                    y, test_size=0.1, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test  = tokenizer.texts_to_sequences(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(s.split()) for s in sentences])\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
    "X_test =pad_sequences(X_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "tockenized_data = data2.copy()\n",
    "tockenized_data['text'] = tockenized_data['text'].apply(lambda x: tokenization(x.lower()))\n",
    "\n",
    "tockenized_data.head()\n",
    "\n",
    "tweet_data = tockenized_data['text']\n",
    "tweet_data[1]\n",
    "\n",
    "tweet_data_array = []\n",
    "\n",
    "for arr in tweet_data:\n",
    "    tweet_data_array.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2590\n"
     ]
    }
   ],
   "source": [
    "# train word2vec model\n",
    "model = Word2Vec(sentences=tweet_data_array, size=100, window=5, workers=3, min_count=1,\n",
    "                 negative=20, iter=100,seed=1000,sg=0)\n",
    "# summarize vocabulary size in model\n",
    "words = list(model.wv.vocab)\n",
    "print('Vocabulary size: %d' % len(words))\n",
    "    \n",
    "# save model in ASCII (word2vec) format\n",
    "filename = './Embedding_Models/embedding_word2vec100iterCBOW.txt'\n",
    "model.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding as a dict\n",
    "def load_embedding(filename):\n",
    "# load embedding into memory, skip first line\n",
    "    file = open(filename,'r')\n",
    "    lines = file.readlines()[1:]\n",
    "    file.close()\n",
    "    # create a map of words to vectors\n",
    "    embedding = dict()\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        # key is string word, value is numpy array for vector\n",
    "        embedding[parts[0]] = np.asarray(parts[1:], dtype='float32')\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for the Embedding layer from a loaded embedding\n",
    "def get_weight_matrix(embedding, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, 100))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = embedding.get(word)\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load embedding from file\n",
    "raw_embedding = load_embedding('./Embedding_Models/embedding_word2vec100iterCBOW.txt')\n",
    "# get vectors in the right order\n",
    "embedding_vectors = get_weight_matrix(raw_embedding, tokenizer.word_index)\n",
    "# create the embedding layer\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_vectors], input_length=max_length, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 23, 100)           1539700   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,540,721\n",
      "Trainable params: 1,021\n",
      "Non-trainable params: 1,539,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy','Precision','Recall'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "386/386 [==============================] - 4s 10ms/step - loss: 0.6347 - accuracy: 0.6469 - precision: 0.5959 - recall: 0.5363 - val_loss: 0.5547 - val_accuracy: 0.7259 - val_precision: 0.7071 - val_recall: 0.6513\n",
      "Epoch 2/50\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.5355 - accuracy: 0.7388 - precision: 0.7086 - recall: 0.6591 - val_loss: 0.5381 - val_accuracy: 0.7464 - val_precision: 0.7211 - val_recall: 0.6974\n",
      "Epoch 3/50\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.5143 - accuracy: 0.7609 - precision: 0.7343 - recall: 0.6891 - val_loss: 0.5352 - val_accuracy: 0.7536 - val_precision: 0.7385 - val_recall: 0.6875\n",
      "Epoch 4/50\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.5065 - accuracy: 0.7640 - precision: 0.7398 - recall: 0.6895 - val_loss: 0.5289 - val_accuracy: 0.7595 - val_precision: 0.7491 - val_recall: 0.6875\n",
      "Epoch 5/50\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.5018 - accuracy: 0.7651 - precision: 0.7433 - recall: 0.6868 - val_loss: 0.5352 - val_accuracy: 0.7449 - val_precision: 0.6985 - val_recall: 0.7467\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=16,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-27-75a57132f8cc>:2: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>313</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>96</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative  Positive\n",
       "Negative       313       113\n",
       "Positive        96       240"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "Y_pred = model.predict_generator(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "def rounding(results):\n",
    "    '''Results needs to be rounded to 0 or 1 for fake or real, respectively'''\n",
    "    if results < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "predictions_final = [rounding(x) for x in Y_pred]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_final).ravel()\n",
    "precision= tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tn + fp +fn+tp)\n",
    "falsePositiveRate = fp / (fp + tn)\n",
    "recall = tp/(tp+fn)\n",
    "f1= 2 * ((recall*precision)/(recall+precision))\n",
    "\n",
    "# Intialise data to Dicts of series. \n",
    "d = {'Value' : pd.Series([accuracy, precision, falsePositiveRate, recall,f1], index =['Accuracy', 'Precision', 'FPR','Recall','F1'])} \n",
    "  \n",
    "# creates Dataframe. \n",
    "results = pd.DataFrame(d) \n",
    "  \n",
    "\n",
    "data = {'Negative':[tn, fn], 'Positive':[fp, tp]} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df= pd.DataFrame(data, index =['Negative', 'Positive']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.725722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.679887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.265258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.696662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "Accuracy   0.725722\n",
       "Precision  0.679887\n",
       "FPR        0.265258\n",
       "Recall     0.714286\n",
       "F1         0.696662"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- performance is bad when the number of iterations is low\n",
    "- skip gram is better for learning infrequent words\n",
    "    - In CBOW the vectors from the context words are averaged before predicting the center word.\n",
    "    - In skip-gram there is no averaging of embedding vectors \n",
    "    - It seems like the model can learn better representations for the rare words when their vectors are not   averaged with the other context words in the process of making the predictions.\n",
    "- This dataset is composed of mostly repeating words, especially the keywords that are used to extract tweets, therefore it is probably better to use CBOW.\n",
    "- CBOW does also yield a better performance.\n",
    "- Pre-trained embeddings have less trainable parameters than the keras embedding layer \n",
    "\n",
    "**30 iterations**\n",
    "- CBOW: 59 F1, 69.9 ACC\n",
    "- SG: 68 F1, 73.6 ACC\n",
    "\n",
    "\n",
    "**50 iterations**\n",
    "- CBOW: 69 F1, 72 ACC\n",
    "- SG: 64 F1, 70 ACC\n",
    "\n",
    "**100 iterations**\n",
    "- CBOW: 67 F1, 72 ACC\n",
    "- SG: 63 F1, 72 ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN +  Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load embedding from file\n",
    "raw_embedding = load_embedding('./Embedding_Models/embedding_word2vec100iterCBOW.txt')\n",
    "# get vectors in the right order\n",
    "embedding_vectors = get_weight_matrix(raw_embedding, tokenizer.word_index)\n",
    "# create the embedding layer\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_vectors], input_length=max_length, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 23, 100)           1539700   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 23, 100)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 23, 128)           29312     \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 64)                12352     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,581,429\n",
      "Trainable params: 41,729\n",
      "Non-trainable params: 1,539,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM,SpatialDropout1D,Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(SimpleRNN(128,return_sequences=True))\n",
    "model.add(SimpleRNN(64,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "386/386 [==============================] - 29s 76ms/step - loss: 0.6386 - accuracy: 0.6730 - val_loss: 0.6440 - val_accuracy: 0.6618\n",
      "Epoch 2/50\n",
      "386/386 [==============================] - 29s 74ms/step - loss: 0.6363 - accuracy: 0.6736 - val_loss: 0.6313 - val_accuracy: 0.6735\n",
      "Epoch 3/50\n",
      "386/386 [==============================] - 29s 75ms/step - loss: 0.6133 - accuracy: 0.7030 - val_loss: 0.5997 - val_accuracy: 0.7128\n",
      "Epoch 4/50\n",
      "386/386 [==============================] - 29s 76ms/step - loss: 0.6126 - accuracy: 0.7009 - val_loss: 0.6036 - val_accuracy: 0.7085\n",
      "Epoch 5/50\n",
      "386/386 [==============================] - 28s 74ms/step - loss: 0.6131 - accuracy: 0.7002 - val_loss: 0.6037 - val_accuracy: 0.7085\n",
      "Epoch 6/50\n",
      "386/386 [==============================] - 29s 74ms/step - loss: 0.6114 - accuracy: 0.7035 - val_loss: 0.6051 - val_accuracy: 0.7085\n",
      "Epoch 7/50\n",
      "386/386 [==============================] - 29s 76ms/step - loss: 0.6108 - accuracy: 0.7041 - val_loss: 0.6043 - val_accuracy: 0.7085\n",
      "Epoch 8/50\n",
      "386/386 [==============================] - 29s 75ms/step - loss: 0.6104 - accuracy: 0.7049 - val_loss: 0.6040 - val_accuracy: 0.7085\n",
      "Epoch 9/50\n",
      "386/386 [==============================] - 29s 76ms/step - loss: 0.6092 - accuracy: 0.7059 - val_loss: 0.6163 - val_accuracy: 0.6968\n",
      "Epoch 10/50\n",
      "386/386 [==============================] - 29s 76ms/step - loss: 0.6098 - accuracy: 0.7072 - val_loss: 0.6149 - val_accuracy: 0.6953\n",
      "Epoch 11/50\n",
      "386/386 [==============================] - 29s 75ms/step - loss: 0.6031 - accuracy: 0.7105 - val_loss: 0.6150 - val_accuracy: 0.6953\n",
      "Epoch 12/50\n",
      "386/386 [==============================] - 29s 76ms/step - loss: 0.6098 - accuracy: 0.7056 - val_loss: 0.6154 - val_accuracy: 0.6953\n",
      "Epoch 13/50\n",
      "386/386 [==============================] - 30s 78ms/step - loss: 0.6264 - accuracy: 0.6722 - val_loss: 0.6963 - val_accuracy: 0.4796\n",
      "Epoch 14/50\n",
      "386/386 [==============================] - 29s 75ms/step - loss: 0.6875 - accuracy: 0.5439 - val_loss: 0.6915 - val_accuracy: 0.5408\n",
      "Epoch 15/50\n",
      "386/386 [==============================] - 29s 75ms/step - loss: 0.6855 - accuracy: 0.5541 - val_loss: 0.6899 - val_accuracy: 0.5569\n",
      "Epoch 16/50\n",
      "386/386 [==============================] - 29s 75ms/step - loss: 0.6721 - accuracy: 0.5773 - val_loss: 0.6229 - val_accuracy: 0.6764\n",
      "Epoch 17/50\n",
      "386/386 [==============================] - 30s 77ms/step - loss: 0.6187 - accuracy: 0.6792 - val_loss: 0.6164 - val_accuracy: 0.6880\n",
      "Epoch 18/50\n",
      "386/386 [==============================] - 30s 77ms/step - loss: 0.6477 - accuracy: 0.6284 - val_loss: 0.6559 - val_accuracy: 0.6224\n",
      "Epoch 19/50\n",
      "386/386 [==============================] - 29s 76ms/step - loss: 0.6245 - accuracy: 0.6676 - val_loss: 0.5991 - val_accuracy: 0.6983\n",
      "Epoch 20/50\n",
      "386/386 [==============================] - 29s 76ms/step - loss: 0.5935 - accuracy: 0.7061 - val_loss: 0.5975 - val_accuracy: 0.7216\n",
      "Epoch 21/50\n",
      "386/386 [==============================] - 29s 76ms/step - loss: 0.5762 - accuracy: 0.7225 - val_loss: 0.5810 - val_accuracy: 0.7259\n",
      "Epoch 22/50\n",
      "386/386 [==============================] - 30s 77ms/step - loss: 0.5623 - accuracy: 0.7382 - val_loss: 0.5737 - val_accuracy: 0.7274\n",
      "Epoch 23/50\n",
      "386/386 [==============================] - 29s 76ms/step - loss: 0.5543 - accuracy: 0.7445 - val_loss: 0.5538 - val_accuracy: 0.7522\n",
      "Epoch 24/50\n",
      "386/386 [==============================] - 29s 76ms/step - loss: 0.5484 - accuracy: 0.7504 - val_loss: 0.5454 - val_accuracy: 0.7536\n",
      "Epoch 25/50\n",
      "386/386 [==============================] - 30s 77ms/step - loss: 0.5369 - accuracy: 0.7531 - val_loss: 0.5579 - val_accuracy: 0.7609\n",
      "Epoch 26/50\n",
      "386/386 [==============================] - 30s 78ms/step - loss: 0.5334 - accuracy: 0.7617 - val_loss: 0.5228 - val_accuracy: 0.7595\n",
      "Epoch 27/50\n",
      "386/386 [==============================] - 30s 79ms/step - loss: 0.5251 - accuracy: 0.7617 - val_loss: 0.5393 - val_accuracy: 0.7507\n",
      "Epoch 28/50\n",
      "386/386 [==============================] - 30s 77ms/step - loss: 0.5283 - accuracy: 0.7611 - val_loss: 0.5267 - val_accuracy: 0.7653\n",
      "Epoch 29/50\n",
      "386/386 [==============================] - 30s 77ms/step - loss: 0.5209 - accuracy: 0.7680 - val_loss: 0.5157 - val_accuracy: 0.7668\n",
      "Epoch 30/50\n",
      "386/386 [==============================] - 30s 78ms/step - loss: 0.5177 - accuracy: 0.7700 - val_loss: 0.5178 - val_accuracy: 0.7653\n",
      "Epoch 31/50\n",
      "386/386 [==============================] - 30s 77ms/step - loss: 0.5118 - accuracy: 0.7695 - val_loss: 0.5234 - val_accuracy: 0.7595\n",
      "Epoch 32/50\n",
      "386/386 [==============================] - 30s 77ms/step - loss: 0.5201 - accuracy: 0.7633 - val_loss: 0.5359 - val_accuracy: 0.7493\n",
      "Epoch 33/50\n",
      "386/386 [==============================] - 31s 79ms/step - loss: 0.5159 - accuracy: 0.7693 - val_loss: 0.5257 - val_accuracy: 0.7595\n",
      "Epoch 34/50\n",
      "386/386 [==============================] - 30s 78ms/step - loss: 0.5126 - accuracy: 0.7653 - val_loss: 0.5133 - val_accuracy: 0.7668\n",
      "Epoch 35/50\n",
      "386/386 [==============================] - 29s 76ms/step - loss: 0.5115 - accuracy: 0.7729 - val_loss: 0.5265 - val_accuracy: 0.7580\n",
      "Epoch 36/50\n",
      "386/386 [==============================] - 31s 81ms/step - loss: 0.5101 - accuracy: 0.7690 - val_loss: 0.5111 - val_accuracy: 0.7711\n",
      "Epoch 37/50\n",
      "386/386 [==============================] - 32s 84ms/step - loss: 0.5098 - accuracy: 0.7658 - val_loss: 0.5283 - val_accuracy: 0.7609\n",
      "Epoch 38/50\n",
      "386/386 [==============================] - 32s 82ms/step - loss: 0.5096 - accuracy: 0.7677 - val_loss: 0.5089 - val_accuracy: 0.7653\n",
      "Epoch 39/50\n",
      "386/386 [==============================] - 31s 81ms/step - loss: 0.5091 - accuracy: 0.7645 - val_loss: 0.5040 - val_accuracy: 0.7653\n",
      "Epoch 40/50\n",
      "386/386 [==============================] - 31s 81ms/step - loss: 0.5070 - accuracy: 0.7766 - val_loss: 0.5114 - val_accuracy: 0.7609\n",
      "Epoch 41/50\n",
      "386/386 [==============================] - 31s 81ms/step - loss: 0.4985 - accuracy: 0.7771 - val_loss: 0.5223 - val_accuracy: 0.7566\n",
      "Epoch 42/50\n",
      "386/386 [==============================] - 31s 81ms/step - loss: 0.4986 - accuracy: 0.7700 - val_loss: 0.5301 - val_accuracy: 0.7522\n",
      "Epoch 43/50\n",
      "386/386 [==============================] - 31s 81ms/step - loss: 0.4961 - accuracy: 0.7708 - val_loss: 0.5251 - val_accuracy: 0.7405\n",
      "Epoch 44/50\n",
      "386/386 [==============================] - 29s 74ms/step - loss: 0.5040 - accuracy: 0.7692 - val_loss: 0.5247 - val_accuracy: 0.7668\n",
      "Epoch 45/50\n",
      "386/386 [==============================] - 34s 88ms/step - loss: 0.5006 - accuracy: 0.7706 - val_loss: 0.5418 - val_accuracy: 0.7493\n",
      "Epoch 46/50\n",
      "386/386 [==============================] - 30s 77ms/step - loss: 0.4875 - accuracy: 0.7848 - val_loss: 0.5142 - val_accuracy: 0.7624\n",
      "Epoch 47/50\n",
      "386/386 [==============================] - 31s 80ms/step - loss: 0.4906 - accuracy: 0.7765 - val_loss: 0.5198 - val_accuracy: 0.7551\n",
      "Epoch 48/50\n",
      "386/386 [==============================] - 31s 80ms/step - loss: 0.4938 - accuracy: 0.7838 - val_loss: 0.5445 - val_accuracy: 0.7434\n",
      "Epoch 49/50\n",
      "386/386 [==============================] - 30s 79ms/step - loss: 0.4918 - accuracy: 0.7778 - val_loss: 0.5237 - val_accuracy: 0.7522\n",
      "Epoch 50/50\n",
      "386/386 [==============================] - 30s 78ms/step - loss: 0.4937 - accuracy: 0.7794 - val_loss: 0.5338 - val_accuracy: 0.7638\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=16,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2vRNN = model.to_json()\n",
    "with open('./NN_Models/word2vec_RNN_model.json', 'w') as json_file:\n",
    "    json_file.write(model_w2vRNN)\n",
    "\n",
    "model.save_weights('./NN_Models/word2vec_RNN_model.h5')\n",
    "\n",
    "print('saved model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>334</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>92</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative  Positive\n",
       "Negative       334        92\n",
       "Positive        92       244"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "Y_pred = model.predict_generator(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "def rounding(results):\n",
    "    '''Results needs to be rounded to 0 or 1 for fake or real, respectively'''\n",
    "    if results < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "predictions_final = [rounding(x) for x in Y_pred]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_final).ravel()\n",
    "precision= tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tn + fp +fn+tp)\n",
    "falsePositiveRate = fp / (fp + tn)\n",
    "recall = tp/(tp+fn)\n",
    "f1= 2 * ((recall*precision)/(recall+precision))\n",
    "\n",
    "# Intialise data to Dicts of series. \n",
    "d = {'Value' : pd.Series([accuracy, precision, falsePositiveRate, recall,f1], index =['Accuracy', 'Precision', 'FPR','Recall','F1'])} \n",
    "  \n",
    "# creates Dataframe. \n",
    "results = pd.DataFrame(d) \n",
    "  \n",
    "\n",
    "data = {'Negative':[tn, fn], 'Positive':[fp, tp]} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df= pd.DataFrame(data, index =['Negative', 'Positive']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.758530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.726190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.215962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.726190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.726190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "Accuracy   0.758530\n",
       "Precision  0.726190\n",
       "FPR        0.215962\n",
       "Recall     0.726190\n",
       "F1         0.726190"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM +  Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 23, 100)           1539700   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 23, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 23, 128)           117248    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,706,421\n",
      "Trainable params: 166,721\n",
      "Non-trainable params: 1,539,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM,SpatialDropout1D,Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(LSTM(64,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "386/386 [==============================] - 34s 87ms/step - loss: 0.5285 - accuracy: 0.7518 - val_loss: 0.5035 - val_accuracy: 0.7653\n",
      "Epoch 2/50\n",
      "386/386 [==============================] - 32s 82ms/step - loss: 0.4804 - accuracy: 0.7861 - val_loss: 0.4945 - val_accuracy: 0.7609\n",
      "Epoch 3/50\n",
      "386/386 [==============================] - 33s 84ms/step - loss: 0.4557 - accuracy: 0.7963 - val_loss: 0.4857 - val_accuracy: 0.7711\n",
      "Epoch 4/50\n",
      "386/386 [==============================] - 32s 82ms/step - loss: 0.4325 - accuracy: 0.8139 - val_loss: 0.4711 - val_accuracy: 0.7857\n",
      "Epoch 5/50\n",
      "386/386 [==============================] - 35s 91ms/step - loss: 0.4145 - accuracy: 0.8224 - val_loss: 0.4885 - val_accuracy: 0.7901\n",
      "Epoch 6/50\n",
      "386/386 [==============================] - 31s 81ms/step - loss: 0.3978 - accuracy: 0.8287 - val_loss: 0.4878 - val_accuracy: 0.7930\n",
      "Epoch 7/50\n",
      "386/386 [==============================] - 31s 80ms/step - loss: 0.3749 - accuracy: 0.8423 - val_loss: 0.4787 - val_accuracy: 0.7901\n",
      "Epoch 8/50\n",
      "386/386 [==============================] - 31s 80ms/step - loss: 0.3637 - accuracy: 0.8449 - val_loss: 0.4968 - val_accuracy: 0.7813\n",
      "Epoch 9/50\n",
      "386/386 [==============================] - 31s 80ms/step - loss: 0.3472 - accuracy: 0.8569 - val_loss: 0.4897 - val_accuracy: 0.7901\n",
      "Epoch 10/50\n",
      "386/386 [==============================] - 31s 81ms/step - loss: 0.3277 - accuracy: 0.8631 - val_loss: 0.5813 - val_accuracy: 0.7915\n",
      "Epoch 11/50\n",
      "386/386 [==============================] - 31s 79ms/step - loss: 0.3177 - accuracy: 0.8701 - val_loss: 0.5705 - val_accuracy: 0.7697\n",
      "Epoch 12/50\n",
      "386/386 [==============================] - 31s 80ms/step - loss: 0.2974 - accuracy: 0.8795 - val_loss: 0.5271 - val_accuracy: 0.7770\n",
      "Epoch 13/50\n",
      "386/386 [==============================] - 31s 80ms/step - loss: 0.2779 - accuracy: 0.8895 - val_loss: 0.6958 - val_accuracy: 0.7668\n",
      "Epoch 14/50\n",
      "386/386 [==============================] - 31s 80ms/step - loss: 0.2697 - accuracy: 0.8920 - val_loss: 0.6181 - val_accuracy: 0.7682\n",
      "Epoch 15/50\n",
      "386/386 [==============================] - 31s 80ms/step - loss: 0.2606 - accuracy: 0.8954 - val_loss: 0.6381 - val_accuracy: 0.7711\n",
      "Epoch 16/50\n",
      "386/386 [==============================] - 31s 81ms/step - loss: 0.2441 - accuracy: 0.9025 - val_loss: 0.5531 - val_accuracy: 0.7828\n",
      "Epoch 17/50\n",
      "386/386 [==============================] - 31s 80ms/step - loss: 0.2273 - accuracy: 0.9080 - val_loss: 0.6450 - val_accuracy: 0.7915\n",
      "Epoch 18/50\n",
      "386/386 [==============================] - 31s 80ms/step - loss: 0.2239 - accuracy: 0.9066 - val_loss: 0.5984 - val_accuracy: 0.7711\n",
      "Epoch 19/50\n",
      "386/386 [==============================] - 32s 83ms/step - loss: 0.2067 - accuracy: 0.9192 - val_loss: 0.7155 - val_accuracy: 0.7799\n",
      "Epoch 20/50\n",
      "386/386 [==============================] - 32s 83ms/step - loss: 0.2026 - accuracy: 0.9184 - val_loss: 0.7189 - val_accuracy: 0.7770\n",
      "Epoch 21/50\n",
      "386/386 [==============================] - 32s 82ms/step - loss: 0.1935 - accuracy: 0.9230 - val_loss: 0.6651 - val_accuracy: 0.7668\n",
      "Epoch 22/50\n",
      "386/386 [==============================] - 32s 84ms/step - loss: 0.1840 - accuracy: 0.9244 - val_loss: 0.7228 - val_accuracy: 0.7770\n",
      "Epoch 23/50\n",
      "386/386 [==============================] - 32s 82ms/step - loss: 0.1724 - accuracy: 0.9307 - val_loss: 0.7593 - val_accuracy: 0.7595\n",
      "Epoch 24/50\n",
      "386/386 [==============================] - 32s 82ms/step - loss: 0.1755 - accuracy: 0.9311 - val_loss: 0.7756 - val_accuracy: 0.7464\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=16,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model!\n"
     ]
    }
   ],
   "source": [
    "model_w2vRNN = model.to_json()\n",
    "with open('./NN_Models/word2vec_LSTM_model.json', 'w') as json_file:\n",
    "    json_file.write(model_w2vRNN)\n",
    "\n",
    "model.save_weights('./NN_Models/word2vec_LSTM_model.h5')\n",
    "\n",
    "print('saved model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>336</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>91</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative  Positive\n",
       "Negative       336        90\n",
       "Positive        91       245"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "Y_pred = model.predict_generator(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "def rounding(results):\n",
    "    '''Results needs to be rounded to 0 or 1 for fake or real, respectively'''\n",
    "    if results < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "predictions_final = [rounding(x) for x in Y_pred]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_final).ravel()\n",
    "precision= tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tn + fp +fn+tp)\n",
    "falsePositiveRate = fp / (fp + tn)\n",
    "recall = tp/(tp+fn)\n",
    "f1= 2 * ((recall*precision)/(recall+precision))\n",
    "\n",
    "# Intialise data to Dicts of series. \n",
    "d = {'Value' : pd.Series([accuracy, precision, falsePositiveRate, recall,f1], index =['Accuracy', 'Precision', 'FPR','Recall','F1'])} \n",
    "  \n",
    "# creates Dataframe. \n",
    "results = pd.DataFrame(d) \n",
    "  \n",
    "\n",
    "data = {'Negative':[tn, fn], 'Positive':[fp, tp]} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df= pd.DataFrame(data, index =['Negative', 'Positive']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.762467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.211268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.730253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "Accuracy   0.762467\n",
       "Precision  0.731343\n",
       "FPR        0.211268\n",
       "Recall     0.729167\n",
       "F1         0.730253"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 23, 100)           1539700   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 23, 100)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 23, 256)           234496    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               164352    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,938,677\n",
      "Trainable params: 398,977\n",
      "Non-trainable params: 1,539,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM,SpatialDropout1D,Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(64,return_sequences=False)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "386/386 [==============================] - 53s 137ms/step - loss: 0.5093 - accuracy: 0.7565 - val_loss: 0.4838 - val_accuracy: 0.7697\n",
      "Epoch 2/50\n",
      "386/386 [==============================] - 51s 132ms/step - loss: 0.4589 - accuracy: 0.7927 - val_loss: 0.4616 - val_accuracy: 0.7784\n",
      "Epoch 3/50\n",
      "386/386 [==============================] - 51s 132ms/step - loss: 0.4253 - accuracy: 0.8101 - val_loss: 0.4729 - val_accuracy: 0.7901\n",
      "Epoch 4/50\n",
      "386/386 [==============================] - 51s 131ms/step - loss: 0.3994 - accuracy: 0.8279 - val_loss: 0.4787 - val_accuracy: 0.7930\n",
      "Epoch 5/50\n",
      "386/386 [==============================] - 52s 135ms/step - loss: 0.3695 - accuracy: 0.8423 - val_loss: 0.4778 - val_accuracy: 0.7959\n",
      "Epoch 6/50\n",
      "386/386 [==============================] - 51s 133ms/step - loss: 0.3479 - accuracy: 0.8501 - val_loss: 0.4739 - val_accuracy: 0.7857\n",
      "Epoch 7/50\n",
      "386/386 [==============================] - 52s 134ms/step - loss: 0.3206 - accuracy: 0.8647 - val_loss: 0.5127 - val_accuracy: 0.7755\n",
      "Epoch 8/50\n",
      "386/386 [==============================] - 52s 134ms/step - loss: 0.2977 - accuracy: 0.8746 - val_loss: 0.5487 - val_accuracy: 0.7813\n",
      "Epoch 9/50\n",
      "386/386 [==============================] - 51s 133ms/step - loss: 0.2776 - accuracy: 0.8792 - val_loss: 0.5176 - val_accuracy: 0.7886\n",
      "Epoch 10/50\n",
      "386/386 [==============================] - 52s 134ms/step - loss: 0.2431 - accuracy: 0.9014 - val_loss: 0.6106 - val_accuracy: 0.7784\n",
      "Epoch 11/50\n",
      "386/386 [==============================] - 53s 137ms/step - loss: 0.2346 - accuracy: 0.9011 - val_loss: 0.5909 - val_accuracy: 0.7770\n",
      "Epoch 12/50\n",
      "386/386 [==============================] - 52s 135ms/step - loss: 0.2171 - accuracy: 0.9139 - val_loss: 0.6201 - val_accuracy: 0.7974\n",
      "Epoch 13/50\n",
      "386/386 [==============================] - 56s 144ms/step - loss: 0.1990 - accuracy: 0.9223 - val_loss: 0.6980 - val_accuracy: 0.7843\n",
      "Epoch 14/50\n",
      "386/386 [==============================] - 52s 134ms/step - loss: 0.1783 - accuracy: 0.9277 - val_loss: 0.7575 - val_accuracy: 0.7391\n",
      "Epoch 15/50\n",
      "386/386 [==============================] - 52s 133ms/step - loss: 0.1791 - accuracy: 0.9244 - val_loss: 0.7491 - val_accuracy: 0.7682\n",
      "Epoch 16/50\n",
      "386/386 [==============================] - 52s 134ms/step - loss: 0.1763 - accuracy: 0.9286 - val_loss: 0.7055 - val_accuracy: 0.7726\n",
      "Epoch 17/50\n",
      "386/386 [==============================] - 51s 133ms/step - loss: 0.1571 - accuracy: 0.9348 - val_loss: 0.7241 - val_accuracy: 0.7813\n",
      "Epoch 18/50\n",
      "386/386 [==============================] - 52s 134ms/step - loss: 0.1537 - accuracy: 0.9380 - val_loss: 0.7592 - val_accuracy: 0.7828\n",
      "Epoch 19/50\n",
      "386/386 [==============================] - 53s 138ms/step - loss: 0.1492 - accuracy: 0.9390 - val_loss: 0.7509 - val_accuracy: 0.7872\n",
      "Epoch 20/50\n",
      "386/386 [==============================] - 61s 159ms/step - loss: 0.1401 - accuracy: 0.9424 - val_loss: 0.8136 - val_accuracy: 0.7741\n",
      "Epoch 21/50\n",
      "386/386 [==============================] - 55s 143ms/step - loss: 0.1390 - accuracy: 0.9427 - val_loss: 0.7671 - val_accuracy: 0.7799\n",
      "Epoch 22/50\n",
      "386/386 [==============================] - 57s 147ms/step - loss: 0.1238 - accuracy: 0.9481 - val_loss: 0.8994 - val_accuracy: 0.7595\n",
      "Epoch 00022: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=16,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model!\n"
     ]
    }
   ],
   "source": [
    "model_w2vBLSTM = model.to_json()\n",
    "with open('./NN_Models/word2vec_BLSTM_model.json', 'w') as json_file:\n",
    "    json_file.write(model_w2vBLSTM)\n",
    "\n",
    "model.save_weights('./NN_Models/word2vec_BLSTM_model.h5')\n",
    "\n",
    "print('saved model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-75a57132f8cc>:2: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>327</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>100</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative  Positive\n",
       "Negative       327        99\n",
       "Positive       100       236"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "Y_pred = model.predict_generator(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "def rounding(results):\n",
    "    '''Results needs to be rounded to 0 or 1 for fake or real, respectively'''\n",
    "    if results < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "predictions_final = [rounding(x) for x in Y_pred]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_final).ravel()\n",
    "precision= tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tn + fp +fn+tp)\n",
    "falsePositiveRate = fp / (fp + tn)\n",
    "recall = tp/(tp+fn)\n",
    "f1= 2 * ((recall*precision)/(recall+precision))\n",
    "\n",
    "# Intialise data to Dicts of series. \n",
    "d = {'Value' : pd.Series([accuracy, precision, falsePositiveRate, recall,f1], index =['Accuracy', 'Precision', 'FPR','Recall','F1'])} \n",
    "  \n",
    "# creates Dataframe. \n",
    "results = pd.DataFrame(d) \n",
    "  \n",
    "\n",
    "data = {'Negative':[tn, fn], 'Positive':[fp, tp]} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df= pd.DataFrame(data, index =['Negative', 'Positive']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.738845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.704478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.232394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.702381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.703428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "Accuracy   0.738845\n",
       "Precision  0.704478\n",
       "FPR        0.232394\n",
       "Recall     0.702381\n",
       "F1         0.703428"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 50)           769850    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 100, 128)          22912     \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 64)                12352     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 805,179\n",
      "Trainable params: 35,329\n",
      "Non-trainable params: 769,850\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM,SpatialDropout1D,Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, \n",
    "                           weights=[embedding_matrix], \n",
    "                           input_length=maxlen, \n",
    "                           trainable=False))\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(SimpleRNN(128,return_sequences=True))\n",
    "model.add(SimpleRNN(64,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "Y_pred = model.predict_generator(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "def rounding(results):\n",
    "    '''Results needs to be rounded to 0 or 1 for fake or real, respectively'''\n",
    "    if results < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "predictions_final = [rounding(x) for x in Y_pred]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_final).ravel()\n",
    "precision= tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tn + fp +fn+tp)\n",
    "falsePositiveRate = fp / (fp + tn)\n",
    "recall = tp/(tp+fn)\n",
    "f1= 2 * ((recall*precision)/(recall+precision))\n",
    "\n",
    "# Intialise data to Dicts of series. \n",
    "d = {'Value' : pd.Series([accuracy, precision, falsePositiveRate, recall,f1], index =['Accuracy', 'Precision', 'FPR','Recall','F1'])} \n",
    "  \n",
    "# creates Dataframe. \n",
    "results = pd.DataFrame(d) \n",
    "  \n",
    "\n",
    "data = {'Negative':[tn, fn], 'Positive':[fp, tp]} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df= pd.DataFrame(data, index =['Negative', 'Positive']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
