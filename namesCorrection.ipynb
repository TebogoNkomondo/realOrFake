{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import keras\n",
    "import pandas as pd\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Dropout, Activation, Embedding, Flatten, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Import libraries\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk \n",
    "# nltk.download()\n",
    "import string\n",
    "import re\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "# import these modules \n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geopandas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import FastMarkerCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = Nominatim(user_agent=\"myGeocoder\")\n",
    "location1 = locator.geocode(\"Braamfontein, Johannesburg\")\n",
    "location2 = locator.geocode(\"Melville, Johannesburg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude = -26.1923213, Longitude = 28.0361983\n",
      "Latitude = -26.1751628, Longitude = 28.0108596\n"
     ]
    }
   ],
   "source": [
    "# print(location.address)\n",
    "print(\"Latitude = {}, Longitude = {}\".format(location1.latitude, location1.longitude))\n",
    "print(\"Latitude = {}, Longitude = {}\".format(location2.latitude, location2.longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "   r = 6371\n",
    "   phi1 = np.radians(lat1)\n",
    "   phi2 = np.radians(lat2)\n",
    "   delta_phi = np.radians(lat2 - lat1)\n",
    "   delta_lambda = np.radians(lon2 - lon1)\n",
    "   a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) *   np.sin(delta_lambda / 2)**2\n",
    "   res = r * (2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a)))\n",
    "   return np.round(res, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.17 km\n"
     ]
    }
   ],
   "source": [
    "print(haversine_distance(location1.latitude, location1.longitude,location2.latitude, location2.longitude),'km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "3   6     NaN      NaN   \n",
       "4   7     NaN      NaN   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0                                Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                               Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...   \n",
       "3                                    13,000 people receive #wildfires evacuation orders in California    \n",
       "4             Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('nlp-getting-started/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/patrick/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "#### removing entries where location values are missing\n",
    "data_after_null_removal = data.copy()\n",
    "data_after_null_removal = data_after_null_removal.dropna(subset=['location'])\n",
    "\n",
    "#punctutation removal\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "data_after_punctuation_removal = data_after_null_removal.copy()\n",
    "data_after_punctuation_removal['text'] = data_after_punctuation_removal['text'].apply(lambda x: clean_text(x))\n",
    "data_after_punctuation_removal['location'] = data_after_punctuation_removal['location'].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>birmingham</td>\n",
       "      <td>bbcmtd wholesale markets ablaze</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>est september bristol</td>\n",
       "      <td>always try bring heavy metal rt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>africa</td>\n",
       "      <td>africanbaze breaking newsnigeria flag set ablaze aba</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>philadelphia pa</td>\n",
       "      <td>crying set ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>london uk</td>\n",
       "      <td>plus side look sky last night ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>10826</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>tn</td>\n",
       "      <td>bright side wrecked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>10829</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>newcastleupontyne uk</td>\n",
       "      <td>hes gone relax thought wife wrecked cake goner mind lol whoops</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>10831</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>vancouver canada</td>\n",
       "      <td>three days work theyve pretty much wrecked hahaha shoutout family one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>10832</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>london</td>\n",
       "      <td>fx forex trading cramer igers words wrecked disneys stock</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>lincoln</td>\n",
       "      <td>engineshed great atmosphere british lion gig tonight hearing wrecked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5080 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword               location  \\\n",
       "31       48   ablaze             birmingham   \n",
       "32       49   ablaze  est september bristol   \n",
       "33       50   ablaze                 africa   \n",
       "34       52   ablaze        philadelphia pa   \n",
       "35       53   ablaze              london uk   \n",
       "...     ...      ...                    ...   \n",
       "7575  10826  wrecked                     tn   \n",
       "7577  10829  wrecked   newcastleupontyne uk   \n",
       "7579  10831  wrecked       vancouver canada   \n",
       "7580  10832  wrecked                london    \n",
       "7581  10833  wrecked                lincoln   \n",
       "\n",
       "                                                                       text  \\\n",
       "31                                         bbcmtd wholesale markets ablaze    \n",
       "32                                         always try bring heavy metal rt    \n",
       "33                    africanbaze breaking newsnigeria flag set ablaze aba    \n",
       "34                                                        crying set ablaze   \n",
       "35                                    plus side look sky last night ablaze    \n",
       "...                                                                     ...   \n",
       "7575                                                   bright side wrecked    \n",
       "7577         hes gone relax thought wife wrecked cake goner mind lol whoops   \n",
       "7579  three days work theyve pretty much wrecked hahaha shoutout family one   \n",
       "7580             fx forex trading cramer igers words wrecked disneys stock    \n",
       "7581  engineshed great atmosphere british lion gig tonight hearing wrecked    \n",
       "\n",
       "      target  \n",
       "31         1  \n",
       "32         0  \n",
       "33         1  \n",
       "34         0  \n",
       "35         0  \n",
       "...      ...  \n",
       "7575       0  \n",
       "7577       0  \n",
       "7579       0  \n",
       "7580       0  \n",
       "7581       0  \n",
       "\n",
       "[5080 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Tockenization\n",
    "\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "tockenized_data = data_after_punctuation_removal.copy()\n",
    "tockenized_data['text'] = tockenized_data['text'].apply(lambda x: tokenization(x.lower()))\n",
    "tockenized_data['location'] = tockenized_data['location'].apply(lambda x: tokenization(x.lower()))\n",
    "\n",
    "# stopword removal \n",
    "data_after_stopword_removal = tockenized_data.copy()\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "data_after_stopword_removal['text'] = data_after_stopword_removal['text'].apply(lambda x: remove_stopwords(x))\n",
    "data_after_stopword_removal['location'] = data_after_stopword_removal['location'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# return to string\n",
    "data_without_tockenization = data_after_stopword_removal.copy()\n",
    "def listToString(s):     \n",
    "    # initialize an empty string \n",
    "    str1 = \" \" \n",
    "    # return string   \n",
    "    return (str1.join(s)) \n",
    "        \n",
    "data_without_tockenization['text'] = data_without_tockenization['text'].apply(lambda x: listToString(x))\n",
    "data_without_tockenization['location'] = data_without_tockenization['location'].apply(lambda x: listToString(x))\n",
    "\n",
    "data_without_tockenization\n",
    "# Removing duplicates\n",
    "#data_after_duplicate_removal = data_without_tockenization.drop_duplicates(subset=['text'])\n",
    "#data_after_duplicate_removal.dropna(subset=['location'], inplace=True)\n",
    "#data_after_duplicate_removal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>birmingham</td>\n",
       "      <td>bbcmtd wholesale markets ablaze</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>est september bristol</td>\n",
       "      <td>always try bring heavy metal rt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>africa</td>\n",
       "      <td>african baze breaking nigeria news flag set ablaze aba</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>philadelphia pa</td>\n",
       "      <td>crying set ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>london united kingdom</td>\n",
       "      <td>plus side look sky last night ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>10826</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>tn</td>\n",
       "      <td>bright side wrecked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>10829</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>newcastle upon tyne united kingdom</td>\n",
       "      <td>hes gone relax thought wife wrecked cake goner mind lol whoops</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>10831</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>vancouver canada</td>\n",
       "      <td>three days work theyve pretty much wrecked hahaha shoutout family one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>10832</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>london</td>\n",
       "      <td>fx forex trading cramer igers words wrecked disneys stock</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>lincoln</td>\n",
       "      <td>engine shed great atmosphere british lion gig tonight hearing wrecked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5080 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword                            location  \\\n",
       "31       48   ablaze                          birmingham   \n",
       "32       49   ablaze               est september bristol   \n",
       "33       50   ablaze                              africa   \n",
       "34       52   ablaze                     philadelphia pa   \n",
       "35       53   ablaze               london united kingdom   \n",
       "...     ...      ...                                 ...   \n",
       "7575  10826  wrecked                                  tn   \n",
       "7577  10829  wrecked  newcastle upon tyne united kingdom   \n",
       "7579  10831  wrecked                    vancouver canada   \n",
       "7580  10832  wrecked                             london    \n",
       "7581  10833  wrecked                             lincoln   \n",
       "\n",
       "                                                                        text  \\\n",
       "31                                          bbcmtd wholesale markets ablaze    \n",
       "32                                          always try bring heavy metal rt    \n",
       "33                   african baze breaking nigeria news flag set ablaze aba    \n",
       "34                                                         crying set ablaze   \n",
       "35                                     plus side look sky last night ablaze    \n",
       "...                                                                      ...   \n",
       "7575                                                    bright side wrecked    \n",
       "7577          hes gone relax thought wife wrecked cake goner mind lol whoops   \n",
       "7579   three days work theyve pretty much wrecked hahaha shoutout family one   \n",
       "7580              fx forex trading cramer igers words wrecked disneys stock    \n",
       "7581  engine shed great atmosphere british lion gig tonight hearing wrecked    \n",
       "\n",
       "      target  \n",
       "31         1  \n",
       "32         0  \n",
       "33         1  \n",
       "34         0  \n",
       "35         0  \n",
       "...      ...  \n",
       "7575       0  \n",
       "7577       0  \n",
       "7579       0  \n",
       "7580       0  \n",
       "7581       0  \n",
       "\n",
       "[5080 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(tweet):\n",
    "\n",
    "    #correct some acronyms while we are at it\n",
    "    tweet = re.sub(\"tnwx\", \"tennessee weather\", tweet)\n",
    "    tweet = re.sub(r\"azwx\", \"arizona weather\", tweet)  \n",
    "    tweet = re.sub(r\"alwx\", \"alabama weather\", tweet)\n",
    "    tweet = re.sub(r\"wordpressdotcom\", \"wordpress\", tweet)      \n",
    "    tweet = re.sub(r\"gawx\", \"georgia weather\", tweet)  \n",
    "    tweet = re.sub(r\"scwx\", \"south carolina weather\", tweet)  \n",
    "    tweet = re.sub(r\"cawx\", \"california weather\", tweet)\n",
    "    tweet = re.sub(r\"usnwsgov\", \"united states national weather service\", tweet) \n",
    "    tweet = re.sub(r\"MH370\", \"malaysia airlines flight 370\", tweet)\n",
    "    tweet = re.sub(r\"okwx\", \"oklahoma city weather\", tweet)\n",
    "    tweet = re.sub(r\"arwx\", \"arkansas weather\", tweet)  \n",
    "    tweet = re.sub(r\"lmao\", \"laughing my ass off\", tweet)  \n",
    "    tweet = re.sub(r\"amirite\", \"am i right\", tweet)\n",
    "    \n",
    "    #and some typos/abbreviations\n",
    "    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n",
    "    tweet = re.sub(r\"w/\", \"with\", tweet)\n",
    "    tweet = re.sub(r\"usagov\", \"usa government\", tweet)\n",
    "    tweet = re.sub(r\"recentlu\", \"recently\", tweet)\n",
    "    tweet = re.sub(r\"ph0tos\", \"photos\", tweet)\n",
    "    tweet = re.sub(r\"exp0sed\", \"exposed\", tweet)\n",
    "    tweet = re.sub(r\"<3\", \"love\", tweet)\n",
    "    tweet = re.sub(r\"amageddon\", \"armageddon\", tweet)\n",
    "    tweet = re.sub(r\"trfc\", \"traffic\", tweet)\n",
    "    tweet = re.sub(r\"windStorm\", \"wind storm\", tweet)\n",
    "    tweet = re.sub(r\"16yr\", \"16 year\", tweet)\n",
    "    tweet = re.sub(r\"traumatised\", \"traumatized\", tweet)\n",
    "    \n",
    "    #hashtags and usernames\n",
    "    tweet = re.sub(r\"irandeal\", \"iran deal\", tweet)\n",
    "    tweet = re.sub(r\"arianagrande\", \"ariana grande\", tweet)\n",
    "    tweet = re.sub(r\"camilacabello97\", \"camila cabello\", tweet) \n",
    "    tweet = re.sub(r\"rondarousey\", \"ronda rousey\", tweet)     \n",
    "    tweet = re.sub(r\"mtvhottest\", \"mtv hottest\", tweet)\n",
    "    tweet = re.sub(r\"trapmusic\", \"trap music\", tweet)\n",
    "    tweet = re.sub(r\"prophetmuhammad\", \"prophet Mmuhammad\", tweet)\n",
    "    tweet = re.sub(r\"PantherAttack\", \"panther attack\", tweet)\n",
    "    tweet = re.sub(r\"strategicpatience\", \"strategic patience\", tweet)\n",
    "    tweet = re.sub(r\"socialnews\", \"social news\", tweet)\n",
    "    tweet = re.sub(r\"idps:\", \"internally displaced people :\", tweet)\n",
    "    tweet = re.sub(r\"artistsUnited\", \"artists united\", tweet)\n",
    "    tweet = re.sub(r\"claytonBryant\", \"clayton bryant\", tweet)\n",
    "    tweet = re.sub(r\"uk\", \"united kingdom\", tweet)\n",
    "    tweet = re.sub(r\"usa\", \"united states of america\", tweet)\n",
    "    tweet = re.sub(r\"ny\", \"new york\", tweet)\n",
    "    tweet = re.sub(r\"newcastleupontyne\", \"newcastle upon tyne\", tweet)\n",
    "    tweet = re.sub(r\"jimmyfallon\", \"jimmy fallon\", tweet)\n",
    "    tweet = re.sub(r\"justinbieber\", \"justin bieber\", tweet)\n",
    "    tweet = re.sub(r\"time2015\", \"time 2015\", tweet)\n",
    "    tweet = re.sub(r\"djicemoon\", \"dj icemoon\", tweet)\n",
    "    tweet = re.sub(r\"livingsafely\", \"living safely\", tweet)\n",
    "    tweet = re.sub(r\"fifa16\", \"fifa 2016\", tweet)\n",
    "    tweet = re.sub(r\"thisiswhywecanthavenicethings\", \"this is why we cannot have nice things\", tweet)\n",
    "    tweet = re.sub(r\"bbcnews\", \"bbc news\", tweet)\n",
    "    tweet = re.sub(r\"undergroundrailraod\", \"underground railraod\", tweet)\n",
    "    tweet = re.sub(r\"c4news\", \"c4 news\", tweet)\n",
    "    tweet = re.sub(r\"mudslide\", \"mud slide\", tweet)\n",
    "    tweet = re.sub(r\"nosurrender\", \"no surrender\", tweet)\n",
    "    tweet = re.sub(r\"notexplained\", \"not explained\", tweet)\n",
    "    tweet = re.sub(r\"greatbritishbakeoff\", \"great british bake off\", tweet)\n",
    "    tweet = re.sub(r\"londonfire\", \"london fire\", tweet)\n",
    "    tweet = re.sub(r\"kotaweather\", \"kota weather\", tweet)\n",
    "    tweet = re.sub(r\"luchaunderground\", \"lucha underground\", tweet)\n",
    "    tweet = re.sub(r\"koin6news\", \"koin 6 news\", tweet)\n",
    "    tweet = re.sub(r\"liveOnK2\", \"live on K2\", tweet)\n",
    "    tweet = re.sub(r\"9newsgoldcoast\", \"9 news gold coast\", tweet)\n",
    "    tweet = re.sub(r\"nikeplus\", \"nike plus\", tweet)\n",
    "    tweet = re.sub(r\"david_cameron\", \"david cameron\", tweet)\n",
    "    tweet = re.sub(r\"peterjukes\", \"peter jukes\", tweet)\n",
    "    tweet = re.sub(r\"mikeparractor\", \"michael parr\", tweet)\n",
    "    tweet = re.sub(r\"4playthursdays\", \"foreplay thursdays\", tweet)\n",
    "    tweet = re.sub(r\"tgf2015\", \"tonti town grape festival\", tweet)\n",
    "    tweet = re.sub(r\"realmandyrain\", \"mandy rain\", tweet)\n",
    "    tweet = re.sub(r\"graysondolan\", \"grayson dolan\", tweet)\n",
    "    tweet = re.sub(r\"apollobrown\", \"apollo brown\", tweet)\n",
    "    tweet = re.sub(r\"saddlebrooke\", \"saddle brooke\", tweet)\n",
    "    tweet = re.sub(r\"tontitowngrape\", \"tonti town grape\", tweet)\n",
    "    tweet = re.sub(r\"abbswinston\", \"abbs winston\", tweet)\n",
    "    tweet = re.sub(r\"shaunKing\", \"sshaun king\", tweet)\n",
    "    tweet = re.sub(r\"meekmill\", \"meek mill\", tweet)\n",
    "    tweet = re.sub(r\"tornadogiveaway\", \"tornado giveaway\", tweet)\n",
    "    tweet = re.sub(r\"grupdates\", \"gr updates\", tweet)\n",
    "    tweet = re.sub(r\"southdowns\", \"south downs\", tweet)\n",
    "    tweet = re.sub(r\"braininjury\", \"brain injury\", tweet)\n",
    "    tweet = re.sub(r\"auspol\", \"australian politics\", tweet)\n",
    "    tweet = re.sub(r\"PlannedParenthood\", \"Planned Parenthood\", tweet)\n",
    "    tweet = re.sub(r\"calgaryweather\", \"calgary weather\", tweet)\n",
    "    tweet = re.sub(r\"weallheartonedirection\", \"we all heart one direction\", tweet)\n",
    "    tweet = re.sub(r\"edsheeran\", \"ed sheeran\", tweet)\n",
    "    tweet = re.sub(r\"trueHeroes\", \"true heroes\", tweet)\n",
    "    tweet = re.sub(r\"complexmag\", \"complex magazine\", tweet)\n",
    "    tweet = re.sub(r\"theadvocatemag\", \"the advocate magazine\", tweet)\n",
    "    tweet = re.sub(r\"cityofcalgary\", \"city of calgary\", tweet)\n",
    "    tweet = re.sub(r\"ebolaoutbreak\", \"ebola outbreak\", tweet)\n",
    "    tweet = re.sub(r\"summerfate\", \"summer fate\", tweet)\n",
    "    tweet = re.sub(r\"ramag\", \"royal academy magazine\", tweet)\n",
    "    tweet = re.sub(r\"offers2go\", \"offers to go\", tweet)\n",
    "    tweet = re.sub(r\"modiministry\", \"modi ministry\", tweet)\n",
    "    tweet = re.sub(r\"taxiways\", \"taxi ways\", tweet)\n",
    "    tweet = re.sub(r\"calum5sos\", \"calum hood\", tweet)\n",
    "    tweet = re.sub(r\"jamesmelville\", \"james melville\", tweet)\n",
    "    tweet = re.sub(r\"jamaicaobserver\", \"jamaica observer\", tweet)\n",
    "    tweet = re.sub(r\"tweetlikeitsseptember11th2001\", \"tweet like it is september 11th 2001\", tweet)\n",
    "    tweet = re.sub(r\"cbplawyers\", \"cbp lawyers\", tweet)\n",
    "    tweet = re.sub(r\"fewmoretweets\", \"few more tweets\", tweet)\n",
    "    tweet = re.sub(r\"blacklivesmatter\", \"black lives matter\", tweet)\n",
    "    tweet = re.sub(r\"nasahurricane\", \"nasa hurricane\", tweet)\n",
    "    tweet = re.sub(r\"onlinecommunities\", \"online communities\", tweet)\n",
    "    tweet = re.sub(r\"humanconsumption\", \"human consumption\", tweet)\n",
    "    tweet = re.sub(r\"typhoon-devastated\", \"typhoon devastated\", tweet)\n",
    "    tweet = re.sub(r\"meat-loving\", \"meat loving\", tweet)\n",
    "    tweet = re.sub(r\"facialabuse\", \"facial abuse\", tweet)\n",
    "    tweet = re.sub(r\"lakecounty\", \"lake county\", tweet)\n",
    "    tweet = re.sub(r\"beingauthor\", \"being author\", tweet)\n",
    "    tweet = re.sub(r\"withheavenly\", \"with heavenly\", tweet)\n",
    "    tweet = re.sub(r\"thanku\", \"thank you\", tweet)\n",
    "    tweet = re.sub(r\"itunesmusic\", \"itunes music\", tweet)\n",
    "    tweet = re.sub(r\"offensivecontent\", \"offensive content\", tweet)\n",
    "    tweet = re.sub(r\"worstsummerjob\", \"worst summer job\", tweet)\n",
    "    tweet = re.sub(r\"harrybecareful\", \"harry be careful\", tweet)\n",
    "    tweet = re.sub(r\"nasasolarsystem\", \"nasa solar system\", tweet)\n",
    "    tweet = re.sub(r\"animalrescue\", \"animal rescue\", tweet)\n",
    "    tweet = re.sub(r\"kurtschlichter\", \"kurt schlichter\", tweet)\n",
    "    tweet = re.sub(r\"throwingknifes\", \"throwing knives\", tweet)\n",
    "    tweet = re.sub(r\"godsLove\", \"god's love\", tweet)\n",
    "    tweet = re.sub(r\"bookboost\", \"book boost\", tweet)\n",
    "    tweet = re.sub(r\"ibooklove\", \"I book love\", tweet)\n",
    "    tweet = re.sub(r\"nestleindia\", \"nestle india\", tweet)\n",
    "    tweet = re.sub(r\"realdonaldtrump\", \"donald trump\", tweet)\n",
    "    tweet = re.sub(r\"davidvonderhaar\", \"david vonderhaar\", tweet)\n",
    "    tweet = re.sub(r\"ceciltheLion\", \"cecil the lion\", tweet)\n",
    "    tweet = re.sub(r\"weathernetwork\", \"weather network\", tweet)\n",
    "    tweet = re.sub(r\"gopdebate\", \"gop debate\", tweet)\n",
    "    tweet = re.sub(r\"rickperry\", \"rick perry\", tweet)\n",
    "    tweet = re.sub(r\"frontpage\", \"front page\", tweet)\n",
    "    tweet = re.sub(r\"newsintweets\", \"news in tweets\", tweet)\n",
    "    tweet = re.sub(r\"viralspell\", \"viral spell\", tweet)\n",
    "    tweet = re.sub(r\"til_now\", \"until now\", tweet)\n",
    "    tweet = re.sub(r\"volcanoinrussia\", \"volcano in russia\", tweet)\n",
    "    tweet = re.sub(r\"zippednews\", \"Zipped news\", tweet)\n",
    "    tweet = re.sub(r\"michelebachman\", \"michele bachman\", tweet)\n",
    "    tweet = re.sub(r\"53inch\", \"53 inch\", tweet)\n",
    "    tweet = re.sub(r\"kerricktrial\", \"kerrick trial\", tweet)\n",
    "    tweet = re.sub(r\"abstorm\", \"alberta storm\", tweet)\n",
    "    tweet = re.sub(r\"beyhive\", \"beyonce hive\", tweet)\n",
    "    tweet = re.sub(r\"rockyfire\", \"rocky fire\", tweet)\n",
    "    tweet = re.sub(r\"listen/buy\", \"listen or buy\", tweet)\n",
    "    tweet = re.sub(r\"artistsunited\", \"artists united\", tweet)\n",
    "    tweet = re.sub(r\"engvsaus\", \"england vs australia\", tweet)\n",
    "    tweet = re.sub(r\"scottwalker\", \"scott walker\", tweet)\n",
    "    tweet = re.sub(r\"africanbaze\", \"african baze\", tweet)\n",
    "    tweet = re.sub(r\"engineshed\", \"engine shed\", tweet)\n",
    "    tweet = re.sub(r\"newsnigeria\", \"nigeria news\", tweet)\n",
    "    return tweet\n",
    "\n",
    "data_without_tockenization['text'] = data_without_tockenization['text'].apply(clean)\n",
    "data_without_tockenization['location'] = data_without_tockenization['location'].apply(clean)\n",
    "data_without_tockenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"please don't use my toothbrush\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install autocorrect\n",
    "from autocorrect import Speller \n",
    "\n",
    "#create function to spell check strings\n",
    "def spell_check(x):\n",
    "    spell = Speller(lang='en')\n",
    "    return \" \".join([spell(i) for i in x.split()])\n",
    "\n",
    "#showcase spellcheck \n",
    "mispelled = \"pleaze don't use my toethbrush\"\n",
    "spell_check(mispelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "from pandas import DataFrame\n",
    "import nltk\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "import corenlp\n",
    "\n",
    "# initializing standford nlp with corenlp library\n",
    "jar = 'stanford-ner/stanford-corenlp-4.1.0.jar'\n",
    "model = 'stanford-ner/english.all.3class.distsim.crf.ser.gz'\n",
    "\n",
    "# Prepare NER tagger with english model\n",
    "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')\n",
    "\n",
    "#############helper functions###############\n",
    "\n",
    "# turn first character in each word to upper case\n",
    "def first_character_to_upper(word):\n",
    "    if len(word) == 0:\n",
    "        return word\n",
    "    else:\n",
    "        return word[0].upper() + word[1:]\n",
    "    #end if-else\n",
    "#end first_character_to_upper\n",
    "\n",
    "# tokenize and tag each word and assign it correct label\n",
    "def word_tagger(df,column):\n",
    "    tokenized_words = []\n",
    "    for index, value in df.iterrows():\n",
    "        text = nltk.word_tokenize(value[column])\n",
    "        text = [first_character_to_upper(word) for word in text]\n",
    "        text = ner_tagger.tag(text)\n",
    "        tokenized_words.append(text)\n",
    "    #end for\n",
    "    return tokenized_words\n",
    "#end word_tagger\n",
    "\n",
    "# find locations in text and store them in a list\n",
    "def location_finder(tokenized_words):\n",
    "    found_locations = []\n",
    "    for i in range(len(tokenized_words)):\n",
    "        for j in range(len(tokenized_words[i])):\n",
    "            if tokenized_words[i][j][1] == 'LOCATION':\n",
    "                key_value = [str(tokenized_words[i][j][0]), i]\n",
    "                found_locations.append(key_value)\n",
    "            #end if\n",
    "        #end for\n",
    "    #end for\n",
    "    return found_locations\n",
    "#end location_finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>tweets</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hawaii</td>\n",
       "      <td>Barack Obama was born in Hawaii and he was elected president in 2008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>africa</td>\n",
       "      <td>Jacob Zuma is the son of the soil and he lives mostly in africa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>america</td>\n",
       "      <td>Donald Trump was not born in america and he always tweets about something stupid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>johannesburg</td>\n",
       "      <td>All policians around the world suck big time, pretoria</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       location  \\\n",
       "0        hawaii   \n",
       "1        africa   \n",
       "2       america   \n",
       "3  johannesburg   \n",
       "\n",
       "                                                                             tweets  \\\n",
       "0              Barack Obama was born in Hawaii and he was elected president in 2008   \n",
       "1                   Jacob Zuma is the son of the soil and he lives mostly in africa   \n",
       "2  Donald Trump was not born in america and he always tweets about something stupid   \n",
       "3                            All policians around the world suck big time, pretoria   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       0  \n",
       "3       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "df = DataFrame({'location':[\"hawaii\",\"africa\", \"america\", \"johannesburg\"],\n",
    "               'tweets': [\"Barack Obama was born in Hawaii and he was elected president in 2008\",\n",
    "        \"Jacob Zuma is the son of the soil and he lives mostly in africa\",\n",
    "        \"Donald Trump was not born in america and he always tweets about something stupid\",\n",
    "        \"All policians around the world suck big time, pretoria\"],\n",
    "               'target': [1, 1, 0, 0]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"United states\" need to be converted to \"usa\" becauses it is not dectected as a location as it is\n",
    "\n",
    "#for i in range(len(found_locations)):\n",
    "#    value = found_locations[i][1]\n",
    "#    key = found_locations[i][0]\n",
    "#    print(value, ' found at row ', key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words = word_tagger(df,'tweets')\n",
    "location_tokenized = word_tagger(df, 'location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_locations = location_finder(tokenized_words)\n",
    "location_locater = location_finder(location_tokenized)\n",
    "print(f'\\n {location_locater} \\n\\n')\n",
    "\n",
    "for i in range(len(found_locations)):\n",
    "    value = found_locations[i][1]\n",
    "    key = found_locations[i][0]\n",
    "    print(key, ' found at row ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hawaii Hawaii\n",
      "##############\n",
      "The tweet might be fake\n",
      "Johannesburg Pretoria\n"
     ]
    }
   ],
   "source": [
    "print(location_locater[0][0], found_locations[0][0])\n",
    "print('##############')\n",
    "for i in range(len(location_locater)):\n",
    "    if location_locater[i][1] != found_locations[i][1]:\n",
    "        continue\n",
    "    elif location_locater[i][0] != found_locations[i][0]:\n",
    "        print(\"The tweet might be fake\")\n",
    "        print(location_locater[i][0],found_locations[i][0])\n",
    "    #end if\n",
    "#end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To be continued#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
