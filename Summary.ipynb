{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset contains 7613 entries.\n",
    "- 0.80% entries are missing a keyword entry.\n",
    "    - These entries will be dropped since they make a small fraction of the dataset.\n",
    "    - The keyword is found within the tweet text hence the keyword column will be disregarded for training.\n",
    "- 33.37% of the entries are missing a location entry.\n",
    "    - This represents a large fraction of the dataset hence dropping is not an option.\n",
    "    - The models will be trained without taking into consideration the dataset.\n",
    "    - Another model in which the missing location entries will be replaced with the top 5 most common locations will be trained.\n",
    "    - The model with the best performance will be used.\n",
    "    - Retweets have different locations.\n",
    "    - The effect of retweets from different locations will be investigated\n",
    "    - It is worth investigating the case where tweets from a city centre will unlikely report on a veld fire.\n",
    "- There are duplicate tweets which are labelled differently.\n",
    "    - These entries will be dropped due to the negative impact which they can have on the model.\n",
    "    - An alternate approach is to hand label the duplicated tweets then drop those that are mislabelled.\n",
    "- The data is ordered by the keyword which was used for extraction.\n",
    "    - Batch training will be done hence data will be shuffled to ensure tweets with the same keyword do not end up in the same batch.\n",
    "### Testing: \n",
    "    - Data will be split into training, validation and testing sets.\n",
    "    - The split ratio is 80% training, 10% validation and 10% testing.\n",
    "    - Training data: This set will be used for training the model.\n",
    "    - Validation data: Validation data will be used to evaluate the model's performance in between batches. This data will be crucial for detecting over-fitting. An early stopping mechanism will be used to prevent over-fitting.\n",
    "    - Testing data: Upon completion of training, the model's performance will be evaluated using the training data. \n",
    "    - The training dataset has a 3:4 ratio for real and fake tweets hence the performance metrics that will be used are accuracy, precision and recall. The main aim will be to balance the precision and recall hence the F1 score will be the most definitive performance metric.\n",
    "    - For choosing an appropriate performance metric, the view of an emergency team using the model to track natural disasters around a country has been assumed. If real tweets are classified as fake, then the users who send the tweets are in danger. If fake tweets are classified as real then the emergency tean will waste resources commuting to an area where there is no natural disaster occuring.\n",
    "    - **Precision**: Talks about how precise/accurate the model. I.e. Out of the tweets which are predicted as real how many of them are actually real?\n",
    "    - Precision is a good measure to determine when the costs of False Positive is high.\n",
    "    - If the precision is not high a lot of fake tweets will get classified as real.\n",
    "    - **Recall**: Calculates how many actual positives the model captures through labelling it True Positive.\n",
    "    - Recall is the preferred performance metric when there is a high cost associated with False Negatives.\n",
    "    - Classifying real tweets as fake could be detrimental to the Tweet sender's safety hence the recall is also important.\n",
    "    - **F1**: Since both the precision and recall have been found to be important metrics, it is better to observe the F1 score in order to try and strike a balance between the 2 metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All text will be set to lower case to ensure every words are ensure the same words with different caps are not read as different words.\n",
    "- Words will be lemmentized(i.e. Inflected forms of a word will be grouped together and processed as a single word). \n",
    "- All links are removed by using HTTP and WWW to identify them.\n",
    "- Words containing numbers will also be removed.\n",
    "- Punctuation will also be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The best way to test different feature extraction is to feed data a Neural Network model and evaluating the model's performance.\n",
    "- The feature extraction techniques that have been used for this application are one-hot encodings and word embeddings. \n",
    "- One-Hot Encodings: The different sentences are represented by one-hot encoded matrices where each column associated with a word that is found within a sentence is represented by a 1 and all other entries 0.\n",
    "- The one-hot encoded matrices are sparse.\n",
    "- Word Embeddings: Word embeddings are able to capture more semantic information in text by representing the information using dense matrices.\n",
    "- **add more defining information for one-hot encodings and word embeddings**\n",
    "- The word embeddings have been split into embeddings trained during training the model itself using the keras embedding layer and pre-trained embeddings using Glove and gensim Word2Vec.\n",
    "- **Keras Embedding Layer**: The embeddings are trained using a supervised Dense(MLP) neural network during the process of training the final model.\n",
    "    - The weights are updated during the training the model using back-propagation.\n",
    "    - The embedding layer therfore contributes to the trainable parameters.\n",
    "    - This method requires many epochs for training as the weights are optimized along with the neural network's weights itself.\n",
    "- **Pre-Trained Embeddings**: These embeddings are trained before training the main model.\n",
    "    - These were done using Glove Embeddings which are trained on the Glove Twitter 6B corpus and Word2Vec which was trained on the natural disasters corpus.\n",
    "    - Both the Glove and Word2Vec models yield similar performance.\n",
    "    - The Word2Vec models were optimized by varying the windows size, number of iterations for training, and using both CBOW and Skip-Gram.\n",
    "    - performance is bad when the number of iterations is low\n",
    "    - Skip-Gram is better for learning infrequent words\n",
    "    - In CBOW the vectors from the context words are averaged before predicting the center word.\n",
    "    - In skip-gram there is no averaging of embedding vectors \n",
    "    - It seems like the model can learn better representations for the rare words when their vectors are not   averaged with the other context words in the process of making the predictions.\n",
    "    - This dataset is composed of mostly repeating words, especially the keywords that are used to extract tweets, therefore it is probably better to use CBOW.\n",
    "    - CBOW does also yield a better performance.\n",
    "    - Pre-trained embeddings have less trainable parameters than the keras embedding layer \n",
    "\n",
    "    **30 iterations**\n",
    "    - CBOW: 59 F1, 69.9 ACC\n",
    "    - SG: 68 F1, 73.6 ACC\n",
    "\n",
    "\n",
    "    **50 iterations**\n",
    "    - CBOW: 69 F1, 72 ACC\n",
    "    - SG: 64 F1, 70 ACC\n",
    "\n",
    "    **100 iterations**\n",
    "    - CBOW: 67 F1, 72 ACC\n",
    "    - SG: 63 F1, 72 ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
