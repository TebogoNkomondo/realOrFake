{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import json\n",
    "import keras\n",
    "import pandas as pd\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Dropout, Activation, Embedding\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Import libraries\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk \n",
    "# nltk.download()\n",
    "import string\n",
    "import re\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "import string\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're still going to use a Tokenizer here, but we don't need to fit it\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "# for human-friendly printing\n",
    "labels = ['fake', 'real']\n",
    "\n",
    "# read in our saved dictionary\n",
    "with open('./Dictionary_Models/glove_models_dictionary.json', 'r') as dictionary_file:\n",
    "    dictionary = json.load(dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_index_array(text):\n",
    "    words = kpt.text_to_word_sequence(text)\n",
    "#     words = pad_sequences(words, padding='post', maxlen=23)\n",
    "#     print(text)\n",
    "    wordIndices = []\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            wordIndices.append(dictionary[word])\n",
    "    return wordIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('./NN_Models/Glove_BLSTM_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "model.load_weights('./NN_Models/Glove_BLSTM_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 100, 50)           769850    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_8 (Spatial (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 100, 256)          183296    \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 128)               164352    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,117,627\n",
      "Trainable params: 347,777\n",
      "Non-trainable params: 769,850\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3606582 ]\n",
      " [0.8805345 ]\n",
      " [0.3035707 ]\n",
      " [0.07187507]]\n",
      "**** real Tweet\n"
     ]
    }
   ],
   "source": [
    "tweetText = []\n",
    "tweetText.append('there is a fire in the mountain top and nobody seems to be on the run')\n",
    "tweetText.append('there is an accident happening on elim street')\n",
    "tweetText.append('the cops shot a kid')\n",
    "tweetText.append('the boys were playing soccer with eden hazard to day')\n",
    "\n",
    "y = []\n",
    "y.append(1)\n",
    "y.append(1)\n",
    "y.append(1)\n",
    "y.append(0)\n",
    "\n",
    "input = []\n",
    "# testArr = convert_text_to_index_array(tweetText)\n",
    "for i,k in enumerate(y):\n",
    "#     y[i] = convert_text_to_index_array(y[i])\n",
    "    tweetText[i] = convert_text_to_index_array(tweetText[i])\n",
    "\n",
    "input = pad_sequences(tweetText, padding='post', maxlen=maxlen)\n",
    "    \n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy','Precision','Recall'])\n",
    "# y = np.array(y)\n",
    "pred = model.predict_generator(input)\n",
    "\n",
    "def rounding(results):\n",
    "    '''Results needs to be rounded to 0 or 1 for fake or real, respectively'''\n",
    "    if results < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "predictions_final = [rounding(x) for x in pred]\n",
    "\n",
    "print(np.array(pred))\n",
    "\n",
    "# print('\\n',tweetText)\n",
    "\n",
    "print('****',labels[np.argmax(pred)], 'Tweet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
