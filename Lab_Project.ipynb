{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3kELKzweMZaU"
   },
   "outputs": [],
   "source": [
    "# !pip install -U -q PyDrive\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WX4N1L4sMc7z"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROkgT8ELNxwZ"
   },
   "outputs": [],
   "source": [
    "downloaded = drive.CreateFile({'id':'1-Hh3pdJlxhHWy42ZqXFDdjjBxe4vhoRg'})\n",
    "downloaded.GetContentFile('train.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "shGyaP_zytVP"
   },
   "source": [
    "# Base Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-xRtolszHr5"
   },
   "source": [
    "## Importing relevant libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "isru0U_VzLu2"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import keras\n",
    "import pandas as pd\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Dropout, Activation, Embedding\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Import libraries\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk \n",
    "# nltk.download()\n",
    "import string\n",
    "import re\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEfaIuWN3KT2"
   },
   "source": [
    "## Exploring data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "VfuxUgGt3RAD",
    "outputId": "d5d40978-95d0-42e5-fa33-594c295c2acc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "3   6     NaN      NaN   \n",
       "4   7     NaN      NaN   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0                                Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                               Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...   \n",
       "3                                    13,000 people receive #wildfires evacuation orders in California    \n",
       "4             Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./nlp-getting-started/train.csv')\n",
    "# Only alter the training variable (#never alter the data variable itself)\n",
    "# training = data\n",
    "# # split the data into train and test set\n",
    "# train, test = train_test_split(train, test_size=0.1, random_state=42, shuffle=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkmCYdOXKPiM"
   },
   "source": [
    "### Analysis\n",
    "- there are 7613 data points\n",
    "- **99.198739%** of the data has **keywords**\n",
    "- **66.73%** of the data has **location** points\n",
    "- the top key word used to extract tweets is **fatalities**\n",
    "- data is ordered in terms of keyword used to extact the tweet from twitter \n",
    "- therefore shuffle the data to mix it.\n",
    "- some of the data contains the # symbol which causes an error when the data is exported onto a numpy array\n",
    "- elements in the **text** column which does not have \" \" marks should not include **,** \n",
    "- data in the **location** column may also include **,** marks which will be read as a column delimeter by **np**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XnpG9wg1Kaqe"
   },
   "source": [
    "### Decisions \n",
    "\n",
    "- the most important columns are the text and target columns\n",
    "- the text column contains information about the tweet\n",
    "- the keyword column can be discarded because the keyword appears within the tweet itself.\n",
    "- the location column can be discarded because only 66.73% have a location value associated with them. Droping 33% of the data is impractical\n",
    "- it is however worth exploring whether location of tweet has an impact on the real or fake status of a tweet\n",
    "\n",
    "- in some locations such as a city centre there cannot be a veld fire - so that is a consideration to be made\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBgMp8HCJhxe"
   },
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VIvSjP1PJfUQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residents asked shelter place notified officers evacuation shelter place orders expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pours school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant cranes holding bridge collapse nearby homes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ariaahrary thetawniest control wild fires california even northern part state troubling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police investigating ebike collided car little portugal ebike rider suffered serious nonlife thr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>latest homes razed northern california wildfire abc news</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                                                                     text  \\\n",
       "0                                                            deeds reason earthquake may allah forgive us   \n",
       "1                                                                   forest fire near la ronge sask canada   \n",
       "2                residents asked shelter place notified officers evacuation shelter place orders expected   \n",
       "3                                                  people receive wildfires evacuation orders california    \n",
       "4                                                got sent photo ruby alaska smoke wildfires pours school    \n",
       "...                                                                                                   ...   \n",
       "7608                                               two giant cranes holding bridge collapse nearby homes    \n",
       "7609              ariaahrary thetawniest control wild fires california even northern part state troubling   \n",
       "7610                                                                                      volcano hawaii    \n",
       "7611  police investigating ebike collided car little portugal ebike rider suffered serious nonlife thr...   \n",
       "7612                                            latest homes razed northern california wildfire abc news    \n",
       "\n",
       "      target  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "7608       1  \n",
       "7609       1  \n",
       "7610       1  \n",
       "7611       1  \n",
       "7612       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### removing entries where location values are missing\n",
    "data_after_null_removal = data.copy()\n",
    "# data_after_null_removal = data_after_null_removal.dropna(subset=['location'])\n",
    "\n",
    "#punctutation removal\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "data_afer_punctuation_removal = data_after_null_removal.copy()\n",
    "data_afer_punctuation_removal['text'] = data_afer_punctuation_removal['text'].apply(lambda x: clean_text(x))\n",
    "data_afer_punctuation_removal.head(10)\n",
    "\n",
    "# Tockenization\n",
    "\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "tockenized_data = data_afer_punctuation_removal.copy()\n",
    "tockenized_data['text'] = tockenized_data['text'].apply(lambda x: tokenization(x.lower()))\n",
    "\n",
    "# stopword removal \n",
    "data_after_stopword_removal = tockenized_data.copy()\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "data_after_stopword_removal['text'] = data_after_stopword_removal['text'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# return to string\n",
    "data_without_tockenization = data_after_stopword_removal.copy()\n",
    "def listToString(s):     \n",
    "    # initialize an empty string \n",
    "    str1 = \" \" \n",
    "    # return string   \n",
    "    return (str1.join(s)) \n",
    "        \n",
    "data_without_tockenization['text'] = data_without_tockenization['text'].apply(lambda x: listToString(x))\n",
    "data_without_tockenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAJ5_I2wLS2w"
   },
   "outputs": [],
   "source": [
    "### train - test split\n",
    "training, testing = train_test_split(data_without_tockenization, test_size=0.1, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObaL-amMDiEt"
   },
   "outputs": [],
   "source": [
    "train = training.copy()\n",
    "test = testing.copy()\n",
    "# get the dependent and independent variables\n",
    "train_x = train['text']\n",
    "train_y = train['target']\n",
    "test_x = test['text']\n",
    "test_y = test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4JIjdRbvw5f"
   },
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_-YWhL2vzi0"
   },
   "outputs": [],
   "source": [
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "\n",
    "# only work with the 3000 most popular words found in our dataset\n",
    "max_words = 10000\n",
    "\n",
    "# create a new Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "# feed our tweets to the Tokenizer\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "# Tokenizers come with a convenient list of words and IDs\n",
    "dictionary = tokenizer.word_index\n",
    "\n",
    "# Saving the dictionary\n",
    "with open('dictionary.json', 'w') as dictionary_file:\n",
    "    json.dump(dictionary, dictionary_file)\n",
    "\n",
    "# padding tockenized text so that it is all the same length(longest word's length).\n",
    "def convert_text_to_index_array(text):\n",
    "    return [dictionary[word] for word in kpt.text_to_word_sequence(text)]\n",
    "\n",
    "allWordIndices = []\n",
    "# for each tweet, change each token to its ID in the Tokenizer's word_index\n",
    "for text in train_x:\n",
    "    wordIndices = convert_text_to_index_array(text)\n",
    "    allWordIndices.append(wordIndices)\n",
    "\n",
    "#array of tweets as indeces(words replaced with indexes)\n",
    "allWordIndices = np.asarray(allWordIndices)\n",
    "\n",
    "# create one-hot matrices out of the indexed tweets\n",
    "train_x = tokenizer.sequences_to_matrix(allWordIndices, mode='binary')\n",
    "# treat the labels as categories\n",
    "train_y = keras.utils.to_categorical(train_y, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gewOSOgE0mWW"
   },
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "wYv4KThy0oT6",
    "outputId": "9c6ba703-40cb-4c38-d3d2-5127f21c60ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "386/386 [==============================] - 18s 48ms/step - loss: 0.5272 - accuracy: 0.7478 - precision: 0.7478 - recall: 0.7478 - val_loss: 0.5572 - val_accuracy: 0.7362 - val_precision: 0.7362 - val_recall: 0.7362\n",
      "Epoch 2/10\n",
      "386/386 [==============================] - 21s 53ms/step - loss: 0.2525 - accuracy: 0.9080 - precision: 0.9080 - recall: 0.9080 - val_loss: 0.5482 - val_accuracy: 0.7843 - val_precision: 0.7843 - val_recall: 0.7843\n",
      "Epoch 3/10\n",
      "386/386 [==============================] - 22s 58ms/step - loss: 0.1261 - accuracy: 0.9569 - precision: 0.9569 - recall: 0.9569 - val_loss: 0.5807 - val_accuracy: 0.7930 - val_precision: 0.7930 - val_recall: 0.7930\n",
      "Epoch 00003: early stopping\n",
      "saved model!\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,), activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(512, activation='sigmoid'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy','Precision','Recall'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1)],\n",
    ")\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('model.h5')\n",
    "\n",
    "print('saved model!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "ERhhWVV23Ehl",
    "outputId": "a8521166-3566-4400-e0d7-9d0d1ae38b75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(history.history.keys())\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training and Validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdShkFnuJWnN"
   },
   "source": [
    "## Testing Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1faniBdPTZXz"
   },
   "outputs": [],
   "source": [
    "\n",
    "# we're still going to use a Tokenizer here, but we don't need to fit it\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "# for human-friendly printing\n",
    "labels = ['fake', 'real']\n",
    "\n",
    "# read in our saved dictionary\n",
    "with open('dictionary.json', 'r') as dictionary_file:\n",
    "    dictionary = json.load(dictionary_file)\n",
    "\n",
    "def convert_text_to_index_array(text):\n",
    "    words = kpt.text_to_word_sequence(text)\n",
    "    wordIndices = []\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            wordIndices.append(dictionary[word])\n",
    "\n",
    "    return wordIndices\n",
    "\n",
    "# read in your saved model structure\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "# and create a model from that\n",
    "model = model_from_json(loaded_model_json)\n",
    "# and weight your nodes with your saved values\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "f = open(\"output.txt\",\"w\")\n",
    "for index_of_interest, text1 in enumerate(test_x):\n",
    "    # format your input for the neural net\n",
    "    testArr = convert_text_to_index_array(text1)\n",
    "    input = tokenizer.sequences_to_matrix([testArr], mode='binary')\n",
    "    # predict which bucket your input belongs in\n",
    "\n",
    "    # format your input for the neural net\n",
    "    testArr = convert_text_to_index_array(text1)\n",
    "    input = tokenizer.sequences_to_matrix([testArr], mode='binary')\n",
    "        # predict which bucket your input belongs in\n",
    "    pred = model.predict(input)\n",
    "\n",
    "    predictions.append(np.argmax(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mGyqH1Npducg",
    "outputId": "3417db05-3167-43d7-eada-9d28807c725e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>340</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>98</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative  Positive\n",
       "Negative       340        86\n",
       "Positive        98       238"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predictions = np.array(predictions)\n",
    "test_y = np.array(test_y)\n",
    "confusion_matrix(test_y, predictions)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_y, predictions).ravel()\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tn + fp +fn +tp)\n",
    "falsePositiveRate = fp / (fp + tn)\n",
    "recall = tp/(tp+fn)\n",
    "f1_score = 2 * ((recall*precision)/(recall+precision))\n",
    "\n",
    "# Intialise data to Dicts of series. \n",
    "d = {'Value' : pd.Series([accuracy, precision, falsePositiveRate, recall,f1_score], index =['Accuracy', 'Precision', 'FPR','Recall','F1'])} \n",
    "  \n",
    "# creates Dataframe. \n",
    "results = pd.DataFrame(d) \n",
    "  \n",
    "\n",
    "data = {'Negative':[tn, fn], 'Positive':[fp, tp]} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df = pd.DataFrame(data, index =['Negative', 'Positive']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.758530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.734568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.201878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.721212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "Accuracy   0.758530\n",
       "Precision  0.734568\n",
       "FPR        0.201878\n",
       "Recall     0.708333\n",
       "F1         0.721212"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDpDt1Vw4hmt"
   },
   "source": [
    "### Summary of Base model\n",
    "- The highest achievable accuracy is 77%\n",
    "- The best FPR is 0.09\n",
    "- Model starts overfitting from the first epoch\n",
    "- Validation loss never goes below ~0.45\n",
    "- Attempts were made to vary the batch size. Large batch sizes yield worse performance. The best performance is at 32 or 16\n",
    "- Increasing the number of layers also results in worse performance. Less layers produce better performance\n",
    "- Drop out layers make little to no difference in performance\n",
    "- Including tweets without the keyword seems to yield better performance\n",
    "- Data cleaning produced a slightly less validation loss but not significant enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-trained Word2vec using Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data_without_tockenization.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize data\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "tockenized_data = data2.copy()\n",
    "tockenized_data['text'] = tockenized_data['text'].apply(lambda x: tokenization(x.lower()))\n",
    "\n",
    "tockenized_data.head()\n",
    "\n",
    "tweet_data = tockenized_data['text']\n",
    "tweet_data[1]\n",
    "\n",
    "tweet_data_array = []\n",
    "# store tweets in array for word2vec\n",
    "for arr in tweet_data:\n",
    "    tweet_data_array.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training own word2vec model\n",
    "vector_size = 512\n",
    "window_size = 10\n",
    "# Create Word2Vec\n",
    "word2vec = Word2Vec(sentences=tweet_data_array,\n",
    "                    size=vector_size, \n",
    "                    window=window_size, \n",
    "                    negative=20,\n",
    "                    iter=50,\n",
    "                    seed=1000,\n",
    "                    workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "word2vec.save('ownWord2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "word2vec = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7fc3e02be430>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word vector\n",
    "X_vecs = word2vec.wv\n",
    "\n",
    "X_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tweet length: 9.545514251937476\n",
      "Max tweet length: 23\n"
     ]
    }
   ],
   "source": [
    "# vector size\n",
    "test_size = int(0.1*len(tweet_data))\n",
    "train_size = len(tweet_data) - test_size\n",
    "\n",
    "avg_length = 0.0\n",
    "max_length = 0\n",
    "\n",
    "for tweet in tweet_data:\n",
    "    if len(tweet) > max_length:\n",
    "        max_length = len(tweet)\n",
    "    avg_length += float(len(tweet))\n",
    "    \n",
    "print('Average tweet length: {}'.format(avg_length / float(len(tweet_data))))\n",
    "print('Max tweet length: {}'.format(max_length))\n",
    "\n",
    "max_tweet_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "### train - test split\n",
    "training, testing = train_test_split(tockenized_data, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "x_train = training['text']\n",
    "y_train = training['target']\n",
    "\n",
    "x_test = testing['text']\n",
    "y_test = testing['target']\n",
    "\n",
    "# variables for storing word2vec representations of tweets\n",
    "X_train = np.zeros((len(training), max_tweet_length, vector_size), dtype=K.floatx())\n",
    "Y_train = np.zeros((len(training), 2), dtype=np.int32)\n",
    "X_test = np.zeros((len(testing), max_tweet_length, vector_size), dtype=K.floatx())\n",
    "Y_test = np.zeros((len(testing), 2), dtype=np.int32)\n",
    "\n",
    "# converting tweets(training set) to word2vec representations\n",
    "train_y = keras.utils.to_categorical(y_train, 2)\n",
    "t=0\n",
    "for index, tweet in enumerate(x_train):\n",
    "    for word in tweet:\n",
    "        if word not in X_vecs:\n",
    "            continue\n",
    "        else:\n",
    "            X_train[index, t, :] = X_vecs[word]\n",
    "            t+=1\n",
    "            \n",
    "            if t == max_tweet_length:\n",
    "                t=0\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 15, 512)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting tweets(testing set) to word2vec representations\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "t=0\n",
    "for index, tweet in enumerate(x_test):\n",
    "    for word in tweet:\n",
    "        if word not in X_vecs:\n",
    "            continue\n",
    "        else:\n",
    "            X_test[index, t, :] = X_vecs[word]\n",
    "            t+=1\n",
    "            \n",
    "            if t == max_tweet_length:\n",
    "                t=0\n",
    "#             print(test_y['target'] ,'\\n')\n",
    "            if test_y[index] == 1:\n",
    "                 Y_test[index, :] = [1.0, 0.0] \n",
    "            else:\n",
    "                Y_test[index, :] = [0.0, 1.0] \n",
    "#             Y_test[index, :] = [1.0, 0.0] if test_y[1] == 0 else [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 10000 but received input with shape [None, 15, 512]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-573faad62ef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m history = model.fit(X_train, Y_train,\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 505\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    506\u001b[0m             *args, **kwds))\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/tebogo/anaconda3/envs/py3-TF2.0/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 10000 but received input with shape [None, 15, 512]\n"
     ]
    }
   ],
   "source": [
    "# using the base model's architecture\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,), activation='relu'))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy','Precision','Recall'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1)],\n",
    ")\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('model.h5')\n",
    "\n",
    "print('saved model!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training own Word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data_without_tockenization.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "tockenized_data = data2.copy()\n",
    "tockenized_data['text'] = tockenized_data['text'].apply(lambda x: tokenization(x.lower()))\n",
    "\n",
    "tockenized_data.head()\n",
    "\n",
    "tweet_data = tockenized_data['text']\n",
    "tweet_data[1]\n",
    "\n",
    "tweet_data_array = []\n",
    "\n",
    "for arr in tweet_data:\n",
    "    tweet_data_array.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 512\n",
    "window_size = 10\n",
    "# Create Word2Vec\n",
    "word2vec = Word2Vec(sentences=tweet_data_array,\n",
    "                    size=vector_size, \n",
    "                    window=window_size, \n",
    "                    negative=20,\n",
    "                    iter=50,\n",
    "                    seed=1000,\n",
    "                    workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7fc3ec29e640>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vecs = word2vec.wv\n",
    "\n",
    "X_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tweet length: 9.545514251937476\n",
      "Max tweet length: 23\n"
     ]
    }
   ],
   "source": [
    "test_size = int(0.1*len(tweet_data))\n",
    "train_size = len(tweet_data) - test_size\n",
    "\n",
    "avg_length = 0.0\n",
    "max_length = 0\n",
    "\n",
    "for tweet in tweet_data:\n",
    "    if len(tweet) > max_length:\n",
    "        max_length = len(tweet)\n",
    "    avg_length += float(len(tweet))\n",
    "    \n",
    "print('Average tweet length: {}'.format(avg_length / float(len(tweet_data))))\n",
    "print('Max tweet length: {}'.format(max_length))\n",
    "\n",
    "max_tweet_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "### train - test split\n",
    "training, testing = train_test_split(tockenized_data, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "training\n",
    "\n",
    "x_train = training['text']\n",
    "y_train = training['target']\n",
    "\n",
    "x_test = testing['text']\n",
    "y_test = testing['target']\n",
    "\n",
    "\n",
    "X_train = np.zeros((len(training), max_tweet_length, vector_size), dtype=K.floatx())\n",
    "Y_train = np.zeros((len(training), 2), dtype=np.int32)\n",
    "X_test = np.zeros((len(testing), max_tweet_length, vector_size), dtype=K.floatx())\n",
    "Y_test = np.zeros((len(testing), 2), dtype=np.int32)\n",
    "\n",
    "train_y = np.array(y_train)\n",
    "\n",
    "t=0\n",
    "for index, tweet in enumerate(x_train):\n",
    "    for word in tweet:\n",
    "        if word not in X_vecs:\n",
    "            continue\n",
    "        else:\n",
    "            X_train[index, t, :] = X_vecs[word]\n",
    "            t+=1\n",
    "            \n",
    "            if t == max_tweet_length:\n",
    "                t=0\n",
    "                \n",
    "            if train_y[index] == 1:\n",
    "                 Y_train[index, :] = [1.0, 0.0] \n",
    "            else:\n",
    "                Y_train[index, :] = [0.0, 1.0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0\n",
    "for index, tweet in enumerate(x_test):\n",
    "    for word in tweet:\n",
    "        if word not in X_vecs:\n",
    "            continue\n",
    "        else:\n",
    "            X_test[index, t, :] = X_vecs[word]\n",
    "            t+=1\n",
    "            \n",
    "            if t == max_tweet_length:\n",
    "                t=0\n",
    "#             print(test_y['target'] ,'\\n')\n",
    "            if test_y[index] == 1:\n",
    "                 Y_test[index, :] = [1.0, 0.0] \n",
    "            else:\n",
    "                Y_test[index, :] = [0.0, 1.0] \n",
    "#             Y_test[index, :] = [1.0, 0.0] if test_y[1] == 0 else [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = keras.utils.to_categorical(y_train, 2)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(512))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','Precision','Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "386/386 [==============================] - 78s 203ms/step - loss: 0.5172 - accuracy: 0.7637 - precision: 0.7637 - recall: 0.7649 - val_loss: 0.4915 - val_accuracy: 0.7609 - val_precision: 0.7609 - val_recall: 0.7609\n",
      "Epoch 2/10\n",
      "386/386 [==============================] - 68s 176ms/step - loss: 0.4705 - accuracy: 0.7848 - precision: 0.7848 - recall: 0.7860 - val_loss: 0.4782 - val_accuracy: 0.7828 - val_precision: 0.7828 - val_recall: 0.7828\n",
      "Epoch 3/10\n",
      "386/386 [==============================] - 75s 193ms/step - loss: 0.4295 - accuracy: 0.8058 - precision: 0.8058 - recall: 0.8071 - val_loss: 0.4752 - val_accuracy: 0.7901 - val_precision: 0.7901 - val_recall: 0.7901\n",
      "Epoch 4/10\n",
      "386/386 [==============================] - 85s 220ms/step - loss: 0.3886 - accuracy: 0.8225 - precision: 0.8225 - recall: 0.8239 - val_loss: 0.4965 - val_accuracy: 0.7843 - val_precision: 0.7843 - val_recall: 0.7843\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3ec2a2be0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 15, 512)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 3s 58ms/step - loss: 0.5199 - accuracy: 0.7756 - precision: 0.7756 - recall: 0.7776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.519886314868927, 0.7755905389785767, 0.7755905389785767, 0.7776315808296204]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_final = np.zeros((len(testing), 2), dtype=np.int32)\n",
    "\n",
    "for ind, lab in Y_test:\n",
    "    print(lab)\n",
    "#     if lab[0] == 1:\n",
    "#         y_test_final[ind] = 1\n",
    "#     else:\n",
    "#         y_test_final[ind] = 0\n",
    "\n",
    "# y_test_final        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-49-5531add9b869>:2: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>66</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>233</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative  Positive\n",
       "Negative        66       360\n",
       "Positive       233       103"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "Y_pred = model.predict_generator(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_y, y_pred).ravel()\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tn + fp +fn +tp)\n",
    "falsePositiveRate = fp / (fp + tn)\n",
    "recall = tp/(tp+fn)\n",
    "f1_score = 2 * ((recall*precision)/(recall+precision))\n",
    "\n",
    "# Intialise data to Dicts of series. \n",
    "d = {'Value' : pd.Series([accuracy, precision, falsePositiveRate, recall,f1_score], index =['Accuracy', 'Precision', 'FPR','Recall','F1'])} \n",
    "  \n",
    "# creates Dataframe. \n",
    "results = pd.DataFrame(d) \n",
    "  \n",
    "\n",
    "data = {'Negative':[tn, fn], 'Positive':[fp, tp]} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df = pd.DataFrame(data, index =['Negative', 'Positive']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.221785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.222462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.845070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.306548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.257822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "Accuracy   0.221785\n",
       "Precision  0.222462\n",
       "FPR        0.845070\n",
       "Recall     0.306548\n",
       "F1         0.257822"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    }
   ],
   "source": [
    "corpus = api.load('text8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "pretrainedModel = Word2Vec(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.save('pretrainedModel.model')\n",
    "word2vec = Word2Vec.load('pretrainedModel.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7fc3504af1c0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vecs = word2vec.wv\n",
    "\n",
    "X_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tweet length: 9.545514251937476\n",
      "Max tweet length: 23\n"
     ]
    }
   ],
   "source": [
    "test_size = int(0.1*len(tweet_data))\n",
    "train_size = len(tweet_data) - test_size\n",
    "\n",
    "avg_length = 0.0\n",
    "max_length = 0\n",
    "\n",
    "for tweet in tweet_data:\n",
    "    if len(tweet) > max_length:\n",
    "        max_length = len(tweet)\n",
    "    avg_length += float(len(tweet))\n",
    "    \n",
    "print('Average tweet length: {}'.format(avg_length / float(len(tweet_data))))\n",
    "print('Max tweet length: {}'.format(max_length))\n",
    "\n",
    "max_tweet_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "### train - test split\n",
    "training, testing = train_test_split(tockenized_data, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "training\n",
    "\n",
    "x_train = training['text']\n",
    "y_train = training['target']\n",
    "\n",
    "x_test = testing['text']\n",
    "y_test = testing['target']\n",
    "\n",
    "\n",
    "X_train = np.zeros((len(training), max_tweet_length, vector_size), dtype=K.floatx())\n",
    "Y_train = np.zeros((len(training), 2), dtype=np.int32)\n",
    "X_test = np.zeros((len(testing), max_tweet_length, vector_size), dtype=K.floatx())\n",
    "Y_test = np.zeros((len(testing), 2), dtype=np.int32)\n",
    "\n",
    "train_y = np.array(y_train)\n",
    "\n",
    "t=0\n",
    "for index, tweet in enumerate(x_train):\n",
    "    for word in tweet:\n",
    "        if word not in X_vecs:\n",
    "            continue\n",
    "        else:\n",
    "            X_train[index, t, :] = X_vecs[word]\n",
    "            t+=1\n",
    "            \n",
    "            if t == max_tweet_length:\n",
    "                t=0\n",
    "                \n",
    "            if train_y[index] == 1:\n",
    "                 Y_train[index, :] = [1.0, 0.0] \n",
    "            else:\n",
    "                Y_train[index, :] = [0.0, 1.0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = np.array(y_test)\n",
    "t=0\n",
    "for index, tweet in enumerate(x_test):\n",
    "    for word in tweet:\n",
    "        if word not in X_vecs:\n",
    "            continue\n",
    "        else:\n",
    "            X_test[index, t, :] = X_vecs[word]\n",
    "            t+=1\n",
    "            \n",
    "            if t == max_tweet_length:\n",
    "                t=0\n",
    "#             print(test_y['target'] ,'\\n')\n",
    "            if test_y[index] == 1:\n",
    "                 Y_test[index, :] = [1.0, 0.0] \n",
    "            else:\n",
    "                Y_test[index, :] = [0.0, 1.0] \n",
    "#             Y_test[index, :] = [1.0, 0.0] if test_y[1] == 0 else [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = keras.utils.to_categorical(y_train, 2)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(512))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','Precision','Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "386/386 [==============================] - 63s 163ms/step - loss: 0.5276 - accuracy: 0.7526 - precision: 0.7526 - recall: 0.7539 - val_loss: 0.4916 - val_accuracy: 0.7697 - val_precision: 0.7697 - val_recall: 0.7697\n",
      "Epoch 2/10\n",
      "270/386 [===================>..........] - ETA: 18s - loss: 0.4755 - accuracy: 0.7759 - precision: 0.7759 - recall: 0.7770"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', mode='min', verbose=1)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,Y_test,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "Y_pred = model.predict_generator(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_y, y_pred).ravel()\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tn + fp +fn +tp)\n",
    "falsePositiveRate = fp / (fp + tn)\n",
    "recall = tp/(tp+fn)\n",
    "f1_score = 2 * ((recall*precision)/(recall+precision))\n",
    "\n",
    "# Intialise data to Dicts of series. \n",
    "d = {'Value' : pd.Series([accuracy, precision, falsePositiveRate, recall,f1_score], index =['Accuracy', 'Precision', 'FPR','Recall','F1'])} \n",
    "  \n",
    "# creates Dataframe. \n",
    "results = pd.DataFrame(d) \n",
    "  \n",
    "\n",
    "data = {'Negative':[tn, fn], 'Positive':[fp, tp]} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df = pd.DataFrame(data, index =['Negative', 'Positive']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
